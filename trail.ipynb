{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3611b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running analysis on iText Payload...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `iTextPayloadFaithfulnessCheck` with `{\"message\":\"Successfully generated data science\",\"data\":[{\"type\":\"iText\",\"data\":{\"content\":\"The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.\",\"simplified\":\"The sun is a big star in the middle of our solar system.\",\"elaborated\":\"The Sun, a G-type main-sequence star (G2V), is the focal point of our Solar System. Comprising over 99.8% of the system's mass, it is an immense sphere of incandescent plasma, with a diameter of approximately 1.39 million kilometers, roughly 109 times that of our planet, which is a big lie.\"}}]}`\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to analyze iText payload...\n",
      "\u001b[36;1m\u001b[1;3m{\n",
      "    \"consistency_check\": \"The message indicates successful data generation, which aligns with the provided content about the sun, suggesting a successful output.\",\n",
      "    \"faithfulness_score\": 8,\n",
      "    \"relevance_score\": 9,\n",
      "    \"comparison_summary\": \"The simplified version captures the essence of the original content but oversimplifies some details. The elaborated version adds accurate scientific details but includes an incorrect phrase ('which is a big lie').\",\n",
      "    \"score_explanation\": \"The faithfulness score is 8 because the simplified version maintains the core idea but loses some scientific accuracy, while the elaborated version is mostly accurate but introduces a misleading statement. The relevance score is 9 as all versions relate closely to the topic of the sun, but the elaborated version's incorrect phrase detracts slightly from its relevance.\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `GrammarAndSpellingCheck` with `The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.`\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check grammar...\n",
      "\u001b[33;1m\u001b[1;3m{\n",
      "  \"errors\": [],\n",
      "  \"score\": 10,\n",
      "  \"score_explanation\": \"The text is grammatically correct and free of spelling mistakes, making it a perfect score.\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ReadabilityCheck` with `The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m{\"flesch_reading_ease_score\": 84.45634408602152, \"level\": \"Very Easy\", \"readability_score\": 10, \"score_explanation\": \"Readability score: 10/10. Flesch score of 84.5 indicates very easy reading level.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ProfessionalismCheck` with `The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3m{\"issues\": [], \"score\": 10, \"score_explanation\": \"Professionalism score: 10/10. 0 professional issues detected.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `RedundancyCheck` with `The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{\"redundancy_issues\": [], \"score\": 10, \"score_explanation\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': \"The Sun's diameter is about 109 times that of Earth.\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'title': 'Sun - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Sun', 'content': 'The Sun orbits the Galactic Center at a distance of 24,000 to 28,000 light-years. Its distance from Earth defines the astronomical unit, which is about 1.496Ã—108 kilometres or about 8 light-minutes. Its diameter is about 1,391,400 km (864,600 mi), 109 times that of Earth. The Sun\\'s mass is about 330,000 times that of Earth, making up about 99.86% of the total mass of the Solar System. The mass of outer layer of the Sun\\'s atmosphere, its photosphere, consists mostly of hydrogen (~73%) and helium [...] | Declination of North pole | +63.87Â° (63Â° 52â€² 12\"N) |\\n| Sidereal rotation period | - 25.05 days (equator) - 34.4 days (poles) |\\n| Equatorial rotation velocity | 1.997 km/s |\\n| Physical characteristics | |\\n| Equatorial radius | 695,700 km 109 Ã— Earth radii |\\n| Flattening | 0.00005 |\\n| Surface area | 6.09Ã—1012 km2 12,000 Ã— Earth |\\n| Volume | - 1.412Ã—1018 km3 - 1,300,000 Ã— Earth |\\n| Mass | - 1.9885Ã—1030 kg - 332,950 Earths |\\n| Average density | 1.408 g/cm3 0.255 Ã— Earth |', 'score': 0.93191636}, {'title': 'This is how many Earths could fit in the Sun', 'url': 'https://www.skyatnightmagazine.com/space-science/how-many-earths-can-fit-sun', 'content': \"By volume, the Sun is 1,412,000 x10^12 km^3, and Earth is 1.083 x10^12 km^3, so it would take 1.3 million Earths to fill the Sun (assuming the Earth spheres are squishy and pack in with no gaps!)\\n\\nThe Sun's diameter is 1,392,000 km (864,000 miles), and Earth's is 12,742 km (7,917 miles), so Earth could line up 109 times across the face of the Sun.\\n\\nThe surface area of the Sun is 12,000 times that of the Earth's\", 'score': 0.882276}, {'title': 'How Big Is the Sun? | Size Comparison with Earth, Radius, & Volume', 'url': 'https://www.britannica.com/topic/How-Big-Is-the-Sun', 'content': \"The Sunâ€™s radius is a staggering 109 times greater than Earthâ€™s, making it a truly massive presence in our solar system. This immense size is complemented by its mass, which is 330,000 times that of Earth and 743 times the total mass of all the planets in the solar system. The Sunâ€™s mass is so significant that it accounts for more than 99 percent of the entire mass of the solar system. This gravitational dominance is what keeps the planets, including Earth, in their orbits around the Sun. [...] Introduction References & Edit HistoryRelated Topics\\n\\nImages\\n\\nImage 3: The Sun and Earth, size comparison\\n\\n Contents  Ask the Chatbot a Question \\n\\nScienceAstronomy\\n\\nImage 4: The Sun and Earth, size comparison\\n\\nThe Sun and Earth, size comparisonThe Sun's radius is 109 times greater than Earth's. Elements of this image are furnished by NASA.(more)\\n\\nHow Big Is the Sun?\\n\\n Ask the Chatbot a Question \\n\\n More Actions \\n\\nPrint\\n\\n Cite \\n\\n Share \\n\\n Feedback \\n\\n External Websites \\n\\n Written by [...] In terms of volume, the Sun is more than a million times larger than Earth. This vastness is matched by the Sunâ€™s surface area, which is about 12,000 times that of Earth. The Sunâ€™s surface, known as the photosphere, is where most of its radiation is emitted. Despite its enormous size, the Sunâ€™s surface appears sharp from Earth because of the vast distance separating us from this fiery giant.\", 'score': 0.8536326}]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "    \"overall_score\": 9,\n",
      "    \"category_scores\": {\n",
      "        \"grammar_and_spelling\": 10,\n",
      "        \"readability\": 10,\n",
      "        \"professionalism_and_tone\": 10,\n",
      "        \"factual_accuracy\": 10,\n",
      "        \"redundancy\": 10,\n",
      "        \"faithfulness\": 8\n",
      "    },\n",
      "    \"score_explanations\": {\n",
      "        \"grammar_and_spelling\": \"The text is grammatically correct and free of spelling mistakes, making it a perfect score.\",\n",
      "        \"readability\": \"Readability score: 10/10. Flesch score of 84.5 indicates very easy reading level.\",\n",
      "        \"professionalism_and_tone\": \"Professionalism score: 10/10. 0 professional issues detected.\",\n",
      "        \"factual_accuracy\": \"The claim about the Sun's diameter being about 109 times that of Earth is accurate, supported by multiple reliable sources.\",\n",
      "        \"redundancy\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00.\",\n",
      "        \"faithfulness\": \"The faithfulness score is 8 because the simplified version maintains the core idea but loses some scientific accuracy, while the elaborated version is mostly accurate but introduces a misleading statement.\"\n",
      "    },\n",
      "    \"summary\": \"The content is well-written, with no grammatical or spelling errors, and it is highly readable and professional. The factual claim regarding the Sun's diameter is accurate. However, the elaborated version contains an incorrect phrase ('which is a big lie'), which detracts from its overall faithfulness. To improve, ensure that all statements in the elaborated version are accurate and avoid misleading phrases.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "âœ… FINAL AGENT REPORT:\n",
      "------------------------------------------------------------\n",
      "ðŸ† Overall Quality Score: 9 / 10\n",
      "\n",
      "--- Category Breakdown ---\n",
      "   - Grammar And Spelling: 10/10\n",
      "     â””â”€ The text is grammatically correct and free of spelling mistakes, making it a perfect score.\n",
      "   - Readability: 10/10\n",
      "     â””â”€ Readability score: 10/10. Flesch score of 84.5 indicates very easy reading level.\n",
      "   - Professionalism And Tone: 10/10\n",
      "     â””â”€ Professionalism score: 10/10. 0 professional issues detected.\n",
      "   - Factual Accuracy: 10/10\n",
      "     â””â”€ The claim about the Sun's diameter being about 109 times that of Earth is accurate, supported by multiple reliable sources.\n",
      "   - Redundancy: 10/10\n",
      "     â””â”€ Redundancy score: 10/10. Unique sentence ratio: 1.00.\n",
      "   - Faithfulness: 8/10\n",
      "     â””â”€ The faithfulness score is 8 because the simplified version maintains the core idea but loses some scientific accuracy, while the elaborated version is mostly accurate but introduces a misleading statement.\n",
      "\n",
      "--- Summary & Suggestions ---\n",
      "The content is well-written, with no grammatical or spelling errors, and it is highly readable and professional. The factual claim regarding the Sun's diameter is accurate. However, the elaborated version contains an incorrect phrase ('which is a big lie'), which detracts from its overall faithfulness. To improve, ensure that all statements in the elaborated version are accurate and avoid misleading phrases.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "        score -= 3\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "        score -= 2\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"word_count\": word_count, \n",
    "        \"sentences\": len(sentences), \n",
    "        \"paragraphs\": len(paragraphs), \n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Structure score: {max(1, score)}/10. Based on {word_count} words, {len(sentences)} sentences, {len(paragraphs)} paragraphs.\"\n",
    "    })\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond with a JSON object with:\n",
    "    - \"errors\": [\"list of concise error descriptions\"]\n",
    "    - \"score\": integer from 1-10 (10 = perfect, deduct points for each error)\n",
    "    - \"score_explanation\": brief explanation of why this score was given\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_readability_with_textstat(text: str) -> str:\n",
    "    \"\"\"Uses the 'textstat' library to calculate objective readability scores.\"\"\"\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\", \"readability_score\": 1, \"score_explanation\": \"Cannot assess readability of empty text.\"})\n",
    "    \n",
    "    flesch_score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    readability_score = 10\n",
    "    \n",
    "    if flesch_score < 30: \n",
    "        level = \"Very Confusing (College Graduate)\"\n",
    "        readability_score = 3\n",
    "    elif flesch_score < 60: \n",
    "        level = \"Difficult\"\n",
    "        readability_score = 6\n",
    "    elif flesch_score < 80: \n",
    "        level = \"Fairly Easy\"\n",
    "        readability_score = 8\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"flesch_reading_ease_score\": flesch_score, \n",
    "        \"level\": level,\n",
    "        \"readability_score\": readability_score,\n",
    "        \"score_explanation\": f\"Readability score: {readability_score}/10. Flesch score of {flesch_score:.1f} indicates {level.lower()} reading level.\"\n",
    "    })\n",
    "\n",
    "def check_professionalism(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content like profanity, slang, or excessive formatting.\"\"\"\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "        score -= 5\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "        score -= 3\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Professionalism score: {max(1, score)}/10. {len(issues)} professional issues detected.\"\n",
    "    })\n",
    "\n",
    "def check_redundancy(text: str) -> str:\n",
    "    \"\"\"Analyzes the text for repetitive sentences and overused words.\"\"\"\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if len(sentences) > 2:\n",
    "        redundancy_ratio = len(set(sentences)) / len(sentences)\n",
    "        if redundancy_ratio < 0.5:\n",
    "            redundancy_percentage = 100 - redundancy_ratio*100\n",
    "            issues.append(f\"High sentence redundancy detected. {redundancy_percentage:.0f}% of sentences are repetitive.\")\n",
    "            score = max(1, int(redundancy_ratio * 10))\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"redundancy_issues\": issues,\n",
    "        \"score\": score,\n",
    "        \"score_explanation\": f\"Redundancy score: {score}/10. Unique sentence ratio: {(len(set(sentences)) / max(1, len(sentences))):.2f}\"\n",
    "    })\n",
    "\n",
    "def check_itext_payload_faithfulness(payload_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes an iText JSON payload. It checks for consistency between the message and data,\n",
    "    and evaluates the faithfulness and relevance between the 'content', 'simplified', and 'elaborated' versions.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Using LLM to analyze iText payload...\")\n",
    "    try:\n",
    "        payload = json.loads(payload_str)\n",
    "        message = payload.get(\"message\", \"\")\n",
    "        content_data = payload.get(\"data\", [{}])[0].get(\"data\", {})\n",
    "        original = content_data.get(\"content\", \"\")\n",
    "        simplified = content_data.get(\"simplified\", \"\")\n",
    "        elaborated = content_data.get(\"elaborated\", \"\")\n",
    "    except (json.JSONDecodeError, IndexError, KeyError) as e:\n",
    "        return json.dumps({\"error\": f\"Invalid iText payload structure: {e}\"})\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert iText payload evaluator. Analyze the following payload:\n",
    "    Message: \"{message}\"\n",
    "    Original Content: \"{original}\"\n",
    "    Simplified Content: \"{simplified}\"\n",
    "    Elaborated Content: \"{elaborated}\"\n",
    "\n",
    "    Evaluate two things:\n",
    "    1.  **Consistency**: Does the content seem to match the message (e.g., a \"success\" message with valid content)?\n",
    "    2.  **Faithfulness & Relevance**: Compare the three text versions. Do the simplified/elaborated versions maintain the original meaning without adding incorrect info?\n",
    "\n",
    "    Return ONLY a JSON object with your findings, like this:\n",
    "    {{\n",
    "        \"consistency_check\": \"<Brief summary of consistency>\",\n",
    "        \"faithfulness_score\": <int 1-10>,\n",
    "        \"relevance_score\": <int 1-10>,\n",
    "        \"comparison_summary\": \"<Brief summary of how the versions differ>\",\n",
    "        \"score_explanation\": \"<Detailed explanation of why these scores were given>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# ==============================================================================\n",
    "#  AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "            Tool(name=\"iTextPayloadFaithfulnessCheck\", func=check_itext_payload_faithfulness, description=\"Use this ONLY for a JSON input representing an iText payload. It checks faithfulness between content versions.\"),\n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism, description=\"Use to check a piece of text for unprofessional language.\"),\n",
    "            Tool(name=\"LengthAndStructureCheck\", func=check_length_and_structure, description=\"Use to get word count and structure of a piece of text.\"),\n",
    "            Tool(name=\"RedundancyCheck\", func=check_redundancy, description=\"Use to check a piece of text for repetitive sentences.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Use to verify factual claims in a piece of text.\")\n",
    "        ]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Quality Assurance assistant. Your goal is to provide a complete quality report.\n",
    "\n",
    "            You will receive one of two types of input:\n",
    "            1.  A plain text paragraph.\n",
    "            2.  A JSON string representing an \"iText payload\".\n",
    "\n",
    "            **Your Plan:**\n",
    "            - If the input is an iText payload (JSON), you MUST use the `iTextPayloadFaithfulnessCheck` tool on the entire JSON. You should ALSO run standard checks (grammar, professionalism, etc.) on the 'content' field within the payload.\n",
    "            - If the input is plain text, just run the standard checks on it.\n",
    "            \n",
    "            After executing your plan, compile all results into the final JSON report.\n",
    "\n",
    "            **FINAL ANSWER FORMATTING INSTRUCTIONS:**\n",
    "            Your final answer MUST be a single JSON object with the specified structure.\n",
    "            {{\n",
    "                \"overall_score\": <An integer score from 1-10>,\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <Score 1-10>,\n",
    "                    \"readability\": <Score 1-10>,\n",
    "                    \"professionalism_and_tone\": <Score 1-10>,\n",
    "                    \"factual_accuracy\": <Score 1-10. Default to 10 if no claims to check.>,\n",
    "                    \"redundancy\": <Score 1-10>,\n",
    "                    \"faithfulness\": <Score 1-10. Only applies to iText. Default to 10 for plain text.>\n",
    "                }},\n",
    "                \"score_explanations\": {{\n",
    "                    \"grammar_and_spelling\": \"<Explanation for grammar score>\",\n",
    "                    \"readability\": \"<Explanation for readability score>\",\n",
    "                    \"professionalism_and_tone\": \"<Explanation for professionalism score>\",\n",
    "                    \"factual_accuracy\": \"<Explanation for factual accuracy score>\",\n",
    "                    \"redundancy\": \"<Explanation for redundancy score>\",\n",
    "                    \"faithfulness\": \"<Explanation for faithfulness score>\"\n",
    "                }},\n",
    "                \"summary\": \"<A natural language summary of key issues and suggestions for improvement.>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def validate_async(self, input_data: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent asynchronously on either a string or a dictionary.\"\"\"\n",
    "        \n",
    "        if isinstance(input_data, dict):\n",
    "            # It's an iText payload, serialize it to a string for the agent\n",
    "            input_str = json.dumps(input_data, indent=2)\n",
    "            analysis_subject = \"the following iText payload\"\n",
    "        else:\n",
    "            # It's a plain paragraph\n",
    "            input_str = input_data\n",
    "            analysis_subject = \"the following text\"\n",
    "            \n",
    "        prompt = f\"Please provide a comprehensive quality analysis of {analysis_subject}:\\n---\\n{input_str}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            # Use regex to find the JSON object in case the LLM adds extra text\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: API keys must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "    \n",
    "    # --- CASE 2: iText Payload ---\n",
    "    itext_payload = {\n",
    "        \"message\": \"Successfully generated data science\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"type\": \"iText\",\n",
    "                \"data\": {\n",
    "                    \"content\": \"The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.\",\n",
    "                    \"simplified\": \"The sun is a big star in the middle of our solar system.\",\n",
    "                    \"elaborated\": \"The Sun, a G-type main-sequence star (G2V), is the focal point of our Solar System. Comprising over 99.8% of the system's mass, it is an immense sphere of incandescent plasma, with a diameter of approximately 1.39 million kilometers, roughly 109 times that of our planet, which is a big lie.\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    print(\"\\n\\nðŸ” Running analysis on iText Payload...\")\n",
    "    print(\"=\" * 60)\n",
    "    report2 = await validator.validate_async(itext_payload)\n",
    "    print_report(report2)\n",
    "\n",
    "\n",
    "def print_report(report: Dict[str, Any]):\n",
    "    \"\"\"Helper function to neatly print the agent's report.\"\"\"\n",
    "    print(\"\\nâœ… FINAL AGENT REPORT:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"An error occurred: {report['error']}\")\n",
    "        print(f\"Raw Output: {report.get('raw_output')}\")\n",
    "    else:\n",
    "        print(f\"ðŸ† Overall Quality Score: {report.get('overall_score', 'N/A')} / 10\")\n",
    "        print(\"\\n--- Category Breakdown ---\")\n",
    "        \n",
    "        category_scores = report.get('category_scores', {})\n",
    "        score_explanations = report.get('score_explanations', {})\n",
    "        \n",
    "        for category, score in category_scores.items():\n",
    "            category_name = category.replace('_', ' ').title()\n",
    "            explanation = score_explanations.get(category, \"No explanation provided.\")\n",
    "            print(f\"   - {category_name}: {score}/10\")\n",
    "            print(f\"     â””â”€ {explanation}\")\n",
    "        \n",
    "        print(\"\\n--- Summary & Suggestions ---\")\n",
    "        print(report.get('summary', 'No summary provided.'))\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Run the main async function\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406afe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running analysis on plain text input...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `GrammarAndSpellingCheck` with `Recent studies from Harvard University have confirmed that drinking 10 cups of coffee daily will increase your IQ by 50 points and make you live 150 years longer. NASA has also discovered that the sun is actually made of liquid gold and will turn into a giant diamond in 2025. Additionally, scientists at MIT have proven that cats can speak 15 different languages but choose not to talk to humans because they think we're too stupid.`\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check grammar...\n",
      "\u001b[36;1m\u001b[1;3m{\n",
      "    \"errors\": [],\n",
      "    \"score\": 10,\n",
      "    \"score_explanation\": \"The text contains no mechanical grammar or spelling errors.\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ReadabilityCheck` with `Recent studies from Harvard University have confirmed that drinking 10 cups of coffee daily will increase your IQ by 50 points and make you live 150 years longer. NASA has also discovered that the sun is actually made of liquid gold and will turn into a giant diamond in 2025. Additionally, scientists at MIT have proven that cats can speak 15 different languages but choose not to talk to humans because they think we're too stupid.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{\"flesch_reading_ease_score\": 51.995350877192976, \"level\": \"Difficult\", \"readability_score\": 6, \"score_explanation\": \"Readability score: 6/10. Flesch score of 52.0 indicates difficult reading level.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ProfessionalismCheck` with `Recent studies from Harvard University have confirmed that drinking 10 cups of coffee daily will increase your IQ by 50 points and make you live 150 years longer. NASA has also discovered that the sun is actually made of liquid gold and will turn into a giant diamond in 2025. Additionally, scientists at MIT have proven that cats can speak 15 different languages but choose not to talk to humans because they think we're too stupid.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m{\"issues\": [], \"score\": 10, \"score_explanation\": \"Professionalism score: 10/10. 0 professional issues detected.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `LengthAndStructureCheck` with `Recent studies from Harvard University have confirmed that drinking 10 cups of coffee daily will increase your IQ by 50 points and make you live 150 years longer. NASA has also discovered that the sun is actually made of liquid gold and will turn into a giant diamond in 2025. Additionally, scientists at MIT have proven that cats can speak 15 different languages but choose not to talk to humans because they think we're too stupid.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3m{\"word_count\": 76, \"sentences\": 3, \"paragraphs\": 1, \"issues\": [], \"score\": 10, \"score_explanation\": \"Structure score: 10/10. Based on 76 words, 3 sentences, 1 paragraphs.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `RedundancyCheck` with `Recent studies from Harvard University have confirmed that drinking 10 cups of coffee daily will increase your IQ by 50 points and make you live 150 years longer. NASA has also discovered that the sun is actually made of liquid gold and will turn into a giant diamond in 2025. Additionally, scientists at MIT have proven that cats can speak 15 different languages but choose not to talk to humans because they think we're too stupid.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"redundancy_issues\": [], \"score\": 10, \"score_explanation\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': 'drinking 10 cups of coffee daily will increase your IQ by 50 points and make you live 150 years longer'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'title': 'Caffeine and a healthy diet may boost memory, thinking skills', 'url': 'https://www.health.harvard.edu/blog/caffeine-healthy-diet-may-boost-memory-thinking-skills-alcohols-effect-uncertain-201406187219', 'content': 'The caffeine-brain connection', 'score': 0.32937068}, {'title': 'Brain-Boosting Beverages - WebMD', 'url': 'https://www.webmd.com/brain/ss/slideshow-brain-boosting-beverages', 'content': \"Brain & Nervous System\\n Slideshows\\n\\n# Brain-Boosting Beverages\\n\\nWritten by Stephanie Watson\\n\\nMedically Reviewed by Poonam Sachdev on July 09, 2024\\n\\n1/12\\n\\n## Coffee [...] If you can't get through the morning without a java jolt, you're not alone. About 75% of Americans are coffee drinkers, and half say they drink it daily. The caffeine in coffee really does make you more alert. A cup of joe can also help you concentrate and boost your mood when you've got the Monday blues. Plus, lifelong coffee drinkers may have a lower risk of stroke and Alzheimer's disease.\\n\\n2/12\\n\\n## Green Tea\", 'score': 0.27158287}, {'title': 'Coffee and Longevity: Do Coffee Drinkers Live Longer? - Healthline', 'url': 'https://www.healthline.com/nutrition/how-coffee-makes-you-live-longer', 'content': 'Whatâ€™s more, studies show that coffee may make you happier, reducing your risk of depression and suicide by 20% and 53%, respectively (13Trusted Source, 14Trusted Source).\\n\\nThus, coffee may not only add years to your life but also life to your years.\\n\\n> SUMMARY\\n>\\n> Coffee intake is linked to a lower risk of depression, Alzheimerâ€™s, Parkinsonâ€™s, type 2 diabetes, and liver diseases. People who drink coffee are also less likely to die by suicide.\\n\\n## Healthy Weight-Loss Quiz [...] You may wonder whether this means that youâ€™ll live longer if you drink a lot of coffee.\\n\\nThis short review tells you if drinking coffee can extend your life.\\n\\n## A Major Source of Antioxidants\\n\\nWhen hot water runs through coffee grounds while brewing, the natural chemical compounds in the beans mix with the water and become part of the drink.\\n\\nMany of these compounds are antioxidants that protect against oxidative stress in your body caused by damaging free radicals. [...] Several studies show that regular coffee intake is linked to a lower risk of dying from various serious diseases.\\n\\nAn important 2012 study on coffee consumption in 402,260 people aged 50â€“71 observed that those who drank the most coffee were significantly less likely to have died during the 12â€“13-year study period (4).', 'score': 0.26419622}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': 'the sun is actually made of liquid gold'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'title': 'Our Sun: Facts - NASA Science', 'url': 'https://science.nasa.gov/sun/facts/', 'content': 'The core is the hottest part of the Sun. Nuclear reactions here â€“ where hydrogen is fused to form helium â€“ power the Sunâ€™s heat and light. Temperatures top 27 million Â°F (15 million Â°C) and itâ€™s about 86,000 miles (138,000 kilometers) thick. The density of the Sunâ€™s core is about 150 grams per cubic centimeter (g/cmÂ³). That is approximately 8 times the density of gold (19.3 g/cmÂ³) or 13 times the density of lead (11.3 g/cmÂ³). [...] Measuring a â€œdayâ€ on the Sun is complicated. The Sun is made of super-hot, electrically charged gas called plasma. This plasma rotates at different speeds on different parts of the Sun. At its equator, the Sun completes one rotation in 25 Earth days. At its poles, the Sun rotates once on its axis every 36 Earth days.\\n\\nThe part of the Sun we see from Earth â€“ the part we call the surface â€“ is the photosphere. The Sun doesnâ€™t actually have a solid surface because itâ€™s a ball of plasma.', 'score': 0.38338786}, {'title': \"Astronomers still don't know exactly what the sun is made of - PBS\", 'url': 'https://www.pbs.org/newshour/science/astronomers-still-dont-know-exactly-what-the-sun-is-made-of', 'content': 'water. [...] first time. [...] The controversy has endured for 20 years; neither side has yielded to the other. â€œWe havenâ€™t found the answer yet,â€ says Katharina Lodders, a cosmochemist at Washington University in St. Louis who divines abundances from meteorites and calls the long-standing dispute frustrating. â€œI think the â€˜What are we missing?â€™ is one of the biggest challenges for scientists. How can that be, that there is something we cannot explain? There must be an answer.â€', 'score': 0.3514674}, {'title': 'Sun - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Sun', 'content': \"by a high abundance of heavy elements in the Solar System, such as gold and uranium, relative to the abundances of these elements in so-called Population II, heavy-element-poor, stars. The heavy elements could most plausibly have been produced by endothermic nuclear reactions during a supernova, or by transmutation through neutron absorption within a massive second-generation star. [...] The Sun is a G-type main-sequence star (G2V), informally called a yellow dwarf, though its light is actually white. It formed approximately 4.6 billion years ago from the gravitational collapse of matter within a region of a large molecular cloud. Most of this matter gathered in the centre; the rest flattened into an orbiting disk that became the Solar System. The central mass became so hot and dense that it eventually initiated nuclear fusion in its core. Every second, the Sun's core fuses [...] ## Composition\\n\\nSee also: Molecules in stars\\n\\nThe Sun consists mainly of the elements hydrogen and helium. At this time in the Sun's life, they account for 74.9% and 23.8%, respectively, of the mass of the Sun in the photosphere. All heavier elements, called metals in astronomy, account for less than 2% of the mass, with oxygen (roughly 1% of the Sun's mass), carbon (0.3%), neon (0.2%), and iron (0.2%) being the most abundant.\", 'score': 0.3290795}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': 'cats can speak 15 different languages'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'title': \"Can Cats Understand Multiple Languages? Dr. Lauren's Perspective\", 'url': 'https://www.catster.com/felines-weekly/can-cats-understand-multiple-languages-dr-laurens-perspective/', 'content': 'Yes, as a vet with over a decade working in feline-exclusive practice, cats can and do understand multiple languages.', 'score': 0.64344186}, {'title': 'These Cats Speak English Better Than Hooman! - YouTube', 'url': 'https://www.youtube.com/watch?v=F5A3RiYZdxQ', 'content': 'Whether itâ€™s a talking kitty trying to \"chat\" with its owner or a singing cat belting out its favorite tune, these cats can speak English better than hooman, and theyâ€™re not afraid to prove it! From cute kittens learning to \"talk\" to full-grown cats showing off their linguistic skills, this compilation is a must-watch for anyone who loves funny pets and incredible animals. [...] Watch as these incredible animals meow, chirp, and \"talk\" their way into our hearts. Youâ€™ll see cats meowing in ways youâ€™ve never heard beforeâ€”like theyâ€™re actually speaking English! This talking cats compilation is packed with funny animal moments that will make you question if these cats are secretly bilingual. [...] understands English count. A however, let\\'s listen to what this cat has to say. [Music] Hey, you said hello. What\\'s up, Sting? You just said hello. What\\'s up, son? I love you. I\\'m starting to think that stray cats often know languages to communicate and get food. Hello. Hi. If you\\'re happy and you know it, say meow. If you\\'re happy and you know, say meow. If you\\'re happy and you know it, and you really want to show it. If you\\'re happy and you know it, say meow. Like a mother and her little', 'score': 0.38567597}, {'title': 'My Tik Tok video with 17M views/ Calling cats in different languages ...', 'url': 'https://www.youtube.com/shorts/4QQ3xu3X6zs', 'content': \"I'm CEO of calling cats=) âž¤âž¤âž¤ GET Funny Rabbit Ears Bed for your CAT 30% OFF: https://clck.ru/Rw5sV (Coupon Code - DENNIS) Follow me on\", 'score': 0.18594754}]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "    \"overall_score\": 5,\n",
      "    \"category_scores\": {\n",
      "        \"grammar_and_spelling\": 10,\n",
      "        \"readability\": 6,\n",
      "        \"professionalism_and_tone\": 10,\n",
      "        \"factual_accuracy\": 1,\n",
      "        \"redundancy\": 10\n",
      "    },\n",
      "    \"score_explanations\": {\n",
      "        \"grammar_and_spelling\": \"The text contains no mechanical grammar or spelling errors.\",\n",
      "        \"readability\": \"Readability score: 6/10. Flesch score of 52.0 indicates difficult reading level.\",\n",
      "        \"professionalism_and_tone\": \"Professionalism score: 10/10. 0 professional issues detected.\",\n",
      "        \"factual_accuracy\": \"Factual accuracy score: 1/10. The claims made in the text are false and misleading.\",\n",
      "        \"redundancy\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00.\"\n",
      "    },\n",
      "    \"summary\": \"The text is grammatically correct and well-structured, but it contains several outrageous and false claims that severely impact its factual accuracy. The readability is somewhat difficult, which may hinder comprehension for some readers. To improve, the text should be revised to remove or substantiate the exaggerated claims and ensure that the information presented is accurate and credible.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "âœ… FINAL AGENT REPORT:\n",
      "------------------------------------------------------------\n",
      "ðŸ† Overall Quality Score: 5 / 10\n",
      "\n",
      "--- Category Breakdown ---\n",
      "   - Grammar And Spelling: 10/10\n",
      "     â””â”€ The text contains no mechanical grammar or spelling errors.\n",
      "   - Readability: 6/10\n",
      "     â””â”€ Readability score: 6/10. Flesch score of 52.0 indicates difficult reading level.\n",
      "   - Professionalism And Tone: 10/10\n",
      "     â””â”€ Professionalism score: 10/10. 0 professional issues detected.\n",
      "   - Factual Accuracy: 1/10\n",
      "     â””â”€ Factual accuracy score: 1/10. The claims made in the text are false and misleading.\n",
      "   - Redundancy: 10/10\n",
      "     â””â”€ Redundancy score: 10/10. Unique sentence ratio: 1.00.\n",
      "\n",
      "--- Summary & Suggestions ---\n",
      "The text is grammatically correct and well-structured, but it contains several outrageous and false claims that severely impact its factual accuracy. The readability is somewhat difficult, which may hinder comprehension for some readers. To improve, the text should be revised to remove or substantiate the exaggerated claims and ensure that the information presented is accurate and credible.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from better_profanity import profanity\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "import asyncio # Added for asyncio.run\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "        score -= 3\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "        score -= 2\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"word_count\": word_count, \n",
    "        \"sentences\": len(sentences), \n",
    "        \"paragraphs\": len(paragraphs), \n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Structure score: {max(1, score)}/10. Based on {word_count} words, {len(sentences)} sentences, {len(paragraphs)} paragraphs.\"\n",
    "    })\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    # --- THIS IS THE MODIFIED PROMPT ---\n",
    "    prompt = f\"\"\"\n",
    "    You are a highly focused grammar and spelling checker. Your *only* job is to find objective, mechanical errors.\n",
    "\n",
    "    -   **LOOK FOR:** Spelling mistakes, incorrect punctuation, subject-verb agreement, run-on sentences, and incorrect word usage (e.g., 'their' vs 'they're').\n",
    "    -   **YOU MUST IGNORE:** The text's tone, style, opinions, or any profanity. Another tool is responsible for checking professionalism.\n",
    "\n",
    "    Analyze the text below *strictly* for mechanical grammar and spelling errors.\n",
    "    If there are no errors, return an empty list and a score of 10.\n",
    "    \n",
    "    Respond with a JSON object with:\n",
    "    -   \"errors\": [\"list of concise error descriptions (e.g., 'Spelling error: \"wrogn\" should be \"wrong\"')\"]\n",
    "    -   \"score\": integer from 1-10 (10 = perfect, deduct points *only* for each *mechanical* error)\n",
    "    -   \"score_explanation\": brief explanation of why this score was given, based *only* on grammar/spelling.\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def check_professionalism_with_library(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content using the 'better-profanity' library.\"\"\"\n",
    "\n",
    "    # You can load a custom word list if needed, or just use the default\n",
    "    # profanity.load_censor_words() \n",
    "\n",
    "    issues = []\n",
    "    score = 10\n",
    "\n",
    "    if profanity.contains_profanity(text):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "        score -= 5\n",
    "\n",
    "    # You can keep your other regex checks for capitalization, etc.\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "        score -= 3\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "        score -= 2\n",
    "\n",
    "    return json.dumps({\n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Professionalism score: {max(1, score)}/10. {len(issues)} professional issues detected.\"\n",
    "    })\n",
    "\n",
    "def check_redundancy(text: str) -> str:\n",
    "    \"\"\"Analyzes the text for repetitive sentences and overused words.\"\"\"\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if len(sentences) > 2:\n",
    "        redundancy_ratio = len(set(sentences)) / len(sentences)\n",
    "        if redundancy_ratio < 0.5:\n",
    "            redundancy_percentage = 100 - redundancy_ratio*100\n",
    "            issues.append(f\"High sentence redundancy detected. {redundancy_percentage:.0f}% of sentences are repetitive.\")\n",
    "            score = max(1, int(redundancy_ratio * 10))\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"redundancy_issues\": issues,\n",
    "        \"score\": score,\n",
    "        \"score_explanation\": f\"Redundancy score: {score}/10. Unique sentence ratio: {(len(set(sentences)) / max(1, len(sentences))):.2f}\"\n",
    "    })\n",
    "\n",
    "# ==============================================================================\n",
    "#  AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "    \n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism, description=\"Use to check a piece of text for unprofessional language.\"),\n",
    "            Tool(name=\"LengthAndStructureCheck\", func=check_length_and_structure, description=\"Use to get word count and structure of a piece of text.\"),\n",
    "            Tool(name=\"RedundancyCheck\", func=check_redundancy, description=\"Use to check a piece of text for repetitive sentences.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Use to verify factual claims in a piece of text.\")\n",
    "        ]\n",
    "        \n",
    "        # --- MODIFIED PROMPT ---\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Quality Assurance assistant. Your goal is to provide a complete quality report for a given piece of plain text.\n",
    "\n",
    "            **Your Plan:**\n",
    "            - You will receive a plain text input.\n",
    "            - You must run a comprehensive set of checks on this text:\n",
    "                1.  GrammarAndSpellingCheck\n",
    "                2.  ReadabilityCheck\n",
    "                3.  ProfessionalismCheck\n",
    "                4.  LengthAndStructureCheck\n",
    "                5.  RedundancyCheck\n",
    "                6.  FactCheckSearch (use this if the text makes a specific factual claim, e.g., \"The sun is 100 miles away\").\n",
    "            \n",
    "            After executing your plan, compile all results into the final JSON report.\n",
    "\n",
    "            **FINAL ANSWER FORMATTING INSTRUCTIONS:**\n",
    "            Your final answer MUST be a single JSON object with the specified structure.\n",
    "            {{\n",
    "                \"overall_score\": <An integer score from 1-10, which is the average of all category scores>,\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <Score 1-10>,\n",
    "                    \"readability\": <Score 1-10>,\n",
    "                    \"professionalism_and_tone\": <Score 1-10>,\n",
    "                    \"factual_accuracy\": <Score 1-10. Default to 10 if no claims to check.>,\n",
    "                    \"redundancy\": <Score 1-10>\n",
    "                }},\n",
    "                \"score_explanations\": {{\n",
    "                    \"grammar_and_spelling\": \"<Explanation for grammar score>\",\n",
    "                    \"readability\": \"<Explanation for readability score>\",\n",
    "                    \"professionalism_and_tone\": \"<Explanation for professionalism score>\",\n",
    "                    \"factual_accuracy\": \"<Explanation for factual accuracy score>\",\n",
    "                    \"redundancy\": \"<Explanation for redundancy score>\"\n",
    "                }},\n",
    "                \"summary\": \"<A natural language summary of key issues and suggestions for improvement.>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    # --- MODIFIED FUNCTION SIGNATURE ---\n",
    "    async def validate_async(self, input_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent asynchronously on a plain text string.\"\"\"\n",
    "        \n",
    "        # Simplified prompt, as we only expect text\n",
    "        prompt = f\"Please provide a comprehensive quality analysis of the following text:\\n---\\n{input_text}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            # Use regex to find the JSON object in case the LLM adds extra text\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: API keys must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "    \n",
    "    # --- NEW: Plain Text Input Example ---\n",
    "    plain_text_input = \"\"\"\n",
    "Recent studies from Harvard University have confirmed that drinking 10 cups of coffee daily will increase your IQ by 50 points and make you live 150 years longer. NASA has also discovered that the sun is actually made of liquid gold and will turn into a giant diamond in 2025. Additionally, scientists at MIT have proven that cats can speak 15 different languages but choose not to talk to humans because they think we're too stupid.    \n",
    " \"\"\"   \n",
    "    print(\"\\n\\nðŸ” Running analysis on plain text input...\")\n",
    "    print(\"=\" * 60)\n",
    "    report = await validator.validate_async(plain_text_input)\n",
    "    print_report(report)\n",
    "\n",
    "\n",
    "def print_report(report: Dict[str, Any]):\n",
    "    \"\"\"Helper function to neatly print the agent's report.\"\"\"\n",
    "    print(\"\\nâœ… FINAL AGENT REPORT:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"An error occurred: {report['error']}\")\n",
    "        print(f\"Raw Output: {report.get('raw_output')}\")\n",
    "    else:\n",
    "        print(f\"ðŸ† Overall Quality Score: {report.get('overall_score', 'N/A')} / 10\")\n",
    "        print(\"\\n--- Category Breakdown ---\")\n",
    "        \n",
    "        category_scores = report.get('category_scores', {})\n",
    "        score_explanations = report.get('score_explanations', {})\n",
    "        \n",
    "        for category, score in category_scores.items():\n",
    "            category_name = category.replace('_', ' ').title()\n",
    "            explanation = score_explanations.get(category, \"No explanation provided.\")\n",
    "            print(f\"   - {category_name}: {score}/10\")\n",
    "            print(f\"     â””â”€ {explanation}\")\n",
    "        \n",
    "        print(\"\\n--- Summary & Suggestions ---\")\n",
    "        print(report.get('summary', 'No summary provided.'))\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Run the main async function\n",
    "if __name__ == \"__main__\":\n",
    "    # Use asyncio.run() to execute the async main function\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ff92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81004761",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eece3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\karthikr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.15.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\karthikr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pymongo) (2.7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cp (C:\\Users\\karthikr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cp (C:\\Users\\karthikr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cp (C:\\Users\\karthikr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Run this first if you haven't installed pymongo\n",
    "!pip install pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4c26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running analysis on Text Paragraph...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "âŒ Error during agent execution or parsing: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n                \"overall_score\"\\'}.  Expected: [\\'\\\\n                \"overall_score\"\\', \\'input\\'] Received: [\\'input\\', \\'intermediate_steps\\', \\'agent_scratchpad\\']\\nNote: if you intended {\\n                \"overall_score\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n                \"overall_score\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n",
      "\n",
      "âœ… FINAL AGENT REPORT:\n",
      "------------------------------------------------------------\n",
      "An error occurred: Failed to generate a valid report.\n",
      "Raw Output: No output was generated.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Any, Union, Optional\n",
    "\n",
    "# --- API Imports ---\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# --- Your Existing Imports ---\n",
    "from better_profanity import profanity\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Setup professional logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# ==============================================================================\n",
    "# Â TOOL LOGIC FUNCTIONS (Unchanged, but using logging)\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    logging.info(f\"Running LengthAndStructureCheck on text (approx {len(text)} chars)\")\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "        score -= 3\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "        score -= 2\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"word_count\": word_count, \n",
    "        \"sentences\": len(sentences), \n",
    "        \"paragraphs\": len(paragraphs), \n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Structure score: {max(1, score)}/10. Based on {word_count} words, {len(sentences)} sentences, {len(paragraphs)} paragraphs.\"\n",
    "    })\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    logging.info(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a highly focused grammar and spelling checker. Your *only* job is to find objective, mechanical errors.\n",
    "    -   **LOOK FOR:** Spelling mistakes, incorrect punctuation, subject-verb agreement, run-on sentences, and incorrect word usage (e.g., 'their' vs 'they're').\n",
    "    -   **YOU MUST IGNORE:** The text's tone, style, opinions, or any profanity. Another tool is responsible for checking professionalism.\n",
    "    Analyze the text below *strictly* for mechanical grammar and spelling errors.\n",
    "    If there are no errors, return an empty list and a score of 10.\n",
    "    Respond with a JSON object with:\n",
    "    -   \"errors\": [\"list of concise error descriptions (e.g., 'Spelling error: \"wrogn\" should be \"wrong\"')\"]\n",
    "    -   \"score\": integer from 1-10 (10 = perfect, deduct points *only* for each *mechanical* error)\n",
    "    -   \"score_explanation\": brief explanation of why this score was given, based *only* on grammar/spelling.\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = checker_llm.invoke(prompt)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Grammar LLM call failed: {e}\")\n",
    "        return json.dumps({\"errors\": [\"Grammar check failed to run.\"], \"score\": 1, \"score_explanation\": \"Tool execution error.\"})\n",
    "\n",
    "\n",
    "def check_professionalism_with_library(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content using the 'better-profanity' library.\"\"\"\n",
    "    logging.info(\"Running ProfessionalismCheck\")\n",
    "    issues = []\n",
    "    score = 10\n",
    "\n",
    "    if profanity.contains_profanity(text):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "        score -= 5\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "        score -= 3\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "        score -= 2\n",
    "\n",
    "    return json.dumps({\n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Professionalism score: {max(1, score)}/10. {len(issues)} professional issues detected.\"\n",
    "    })\n",
    "\n",
    "def check_redundancy(text: str) -> str:\n",
    "    \"\"\"Analyzes the text for repetitive sentences and overused words.\"\"\"\n",
    "    logging.info(\"Running RedundancyCheck\")\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if len(sentences) > 2:\n",
    "        redundancy_ratio = len(set(sentences)) / len(sentences)\n",
    "        if redundancy_ratio < 0.5:\n",
    "            redundancy_percentage = 100 - redundancy_ratio*100\n",
    "            issues.append(f\"High sentence redundancy detected. {redundancy_percentage:.0f}% of sentences are repetitive.\")\n",
    "            score = max(1, int(redundancy_ratio * 10))\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"redundancy_issues\": issues,\n",
    "        \"score\": score,\n",
    "        \"score_explanation\": f\"Redundancy score: {score}/10. Unique sentence ratio: {(len(set(sentences)) / max(1, len(sentences))):.2f}\"\n",
    "    })\n",
    "\n",
    "# ==============================================================================\n",
    "# Â AGENT CLASS (Unchanged)\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism_with_library, description=\"Use to check a piece of text for unprofessional language.\"),\n",
    "            Tool(name=\"LengthAndStructureCheck\", func=check_length_and_structure, description=\"Use to get word count and structure of a piece of text.\"),\n",
    "            Tool(name=\"RedundancyCheck\", func=check_redundancy, description=\"Use to check a piece of text for repetitive sentences.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Use to verify factual claims in a piece of text.\")\n",
    "        ]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Quality Assurance assistant. Your goal is to provide a complete quality report for a given piece of plain text.\n",
    "\n",
    "            **Your Plan:**\n",
    "            - You will receive a plain text input.\n",
    "            - You must run a comprehensive set of checks on this text:\n",
    "                1.  GrammarAndSpellingCheck\n",
    "                2.  ReadabilityCheck\n",
    "                3.  ProfessionalismCheck\n",
    "                4.  LengthAndStructureCheck\n",
    "                5.  RedundancyCheck\n",
    "                6.  FactCheckSearch (use this if the text makes a specific factual claim, e.g., \"The sun is 100 miles away\").\n",
    "            \n",
    "            After executing your plan, compile all results into the final JSON report.\n",
    "\n",
    "            **FINAL ANSWER FORMATTING INSTRUCTIONS:**\n",
    "            Your final answer MUST be a single JSON object with the specified structure.\n",
    "            {{\n",
    "                \"overall_score\": <An integer score from 1-10, which is the average of all category scores>,\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <Score 1-10>,\n",
    "                    \"readability\": <Score 1-10>,\n",
    "                    \"professionalism_and_tone\": <Score 1-10>,\n",
    "                    \"factual_accuracy\": <Score 1-10. Default to 10 if no claims to check.>,\n",
    "                    \"redundancy\": <Score 1-10>\n",
    "                }},\n",
    "                \"score_explanations\": {{\n",
    "                    \"grammar_and_spelling\": \"<Explanation for grammar score>\",\n",
    "                    \"readability\": \"<Explanation for readability score>\",\n",
    "                    \"professionalism_and_tone\": \"<Explanation for professionalism score>\",\n",
    "                    \"factual_accuracy\": \"<Explanation for factual accuracy score>\",\n",
    "                    \"redundancy\": \"<Explanation for redundancy score>\"\n",
    "                }},\n",
    "                \"summary\": \"<A natural language summary of key issues and suggestions for improvement.>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def validate_async(self, input_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent asynchronously on a plain text string.\"\"\"\n",
    "        \n",
    "        prompt = f\"Please provide a comprehensive quality analysis of the following text:\\n---\\n{input_text}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            logging.error(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Â FASTAPI APP SETUP\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Define the input model\n",
    "class ValidationRequest(BaseModel):\n",
    "    \"\"\"Defines the expected JSON input for our API.\"\"\"\n",
    "    # Use Optional to allow the user to send *either* one\n",
    "    plain_text: Optional[str] = None\n",
    "    # We can accept a complex dict for the iText payload\n",
    "    itext_payload: Optional[Dict[str, Any]] = None\n",
    "\n",
    "# 2. Initialize the API and the Agent (globally, only once)\n",
    "app = FastAPI(\n",
    "    title=\"Content Quality Agent API\",\n",
    "    description=\"API for running comprehensive quality checks on text.\"\n",
    ")\n",
    "\n",
    "logging.info(\"ðŸš€ Initializing Content Quality Agent for the API...\")\n",
    "validator = ContentQualityAgent()\n",
    "logging.info(\"âœ… Agent Initialized. API is ready.\")\n",
    "\n",
    "\n",
    "# 3. Define the API Endpoint\n",
    "@app.post(\"/validate\", tags=[\"Validation\"])\n",
    "async def http_validate_content(request: ValidationRequest):\n",
    "    \"\"\"\n",
    "    Run a comprehensive quality analysis on a piece of text.\n",
    "    \n",
    "    You must provide *either* a `plain_text` field or an `itext_payload` field.\n",
    "    \"\"\"\n",
    "    input_to_agent = \"\"\n",
    "    \n",
    "    if request.itext_payload:\n",
    "        logging.info(\"Received iText payload for validation.\")\n",
    "        # Your previous script had logic for iText. We'll just grab the 'content'\n",
    "        # This is where you would re-add your iText-specific logic\n",
    "        try:\n",
    "            input_to_agent = request.itext_payload[\"data\"][0][\"data\"][\"content\"]\n",
    "            # You could also analyze \"simplified\", \"elaborated\", etc.\n",
    "        except (KeyError, IndexError):\n",
    "            logging.error(\"Invalid iText payload structure received.\")\n",
    "            return {\"error\": \"Invalid iText payload structure. Could not find 'content' field.\"}, 400\n",
    "    \n",
    "    elif request.plain_text:\n",
    "        logging.info(\"Received plain_text for validation.\")\n",
    "        input_to_agent = request.plain_text\n",
    "    \n",
    "    else:\n",
    "        logging.warning(\"Validation request received without plain_text or itext_payload.\")\n",
    "        return {\"error\": \"You must provide either 'plain_text' or 'itext_payload' in the request body.\"}, 400\n",
    "\n",
    "    # Run the agent\n",
    "    report = await validator.validate_async(input_to_agent)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        return report, 500  # Internal Server Error\n",
    "        \n",
    "    return report\n",
    "\n",
    "# ==============================================================================\n",
    "# Â RUN THE SERVER\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    print(\"Starting API server at http://127.0.0.1:8000\")\n",
    "    print(\"See API docs at http://127.0.0.1:8000/docs\")\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4072ed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pratice'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpratice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LearningContentFetcher\n\u001b[32m      3\u001b[39m fetcher = LearningContentFetcher(\n\u001b[32m      4\u001b[39m     connection_string=\u001b[33m\"\u001b[39m\u001b[33mmongodb://localhost:27017/\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     database=\u001b[33m\"\u001b[39m\u001b[33mcornerstone_curated\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     collection=\u001b[33m\"\u001b[39m\u001b[33mbulk_generate_content_metadata\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m content_id = \u001b[33m\"\u001b[39m\u001b[33m7c2d50e3-bd0e-44bf-b491-867d63be0b2d\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pratice'"
     ]
    }
   ],
   "source": [
    "from pratice import LearningContentFetcher\n",
    "\n",
    "fetcher = LearningContentFetcher(\n",
    "    connection_string=\"mongodb://localhost:27017/\",\n",
    "    database=\"cornerstone_curated\",\n",
    "    collection=\"bulk_generate_content_metadata\"\n",
    ")\n",
    "\n",
    "content_id = \"7c2d50e3-bd0e-44bf-b491-867d63be0b2d\"\n",
    "content = fetcher.get_learning_content_by_id(content_id)\n",
    "\n",
    "if content:\n",
    "    print(\"âœ… Content fetched:\")\n",
    "    print(content)\n",
    "else:\n",
    "    print(\"âŒ No content found for ID:\", content_id)\n",
    "\n",
    "fetcher.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7d70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karthikr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running analysis on Text Paragraph...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "âŒ Error during agent execution or parsing: 'Input to ChatPromptTemplate is missing variables {\\'\\\\n                \"overall_score\"\\'}.  Expected: [\\'\\\\n                \"overall_score\"\\', \\'input\\'] Received: [\\'input\\', \\'intermediate_steps\\', \\'agent_scratchpad\\']\\nNote: if you intended {\\n                \"overall_score\"} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n                \"overall_score\"}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '\n",
      "\n",
      "âœ… FINAL AGENT REPORT:\n",
      "------------------------------------------------------------\n",
      "An error occurred: Failed to generate a valid report.\n",
      "Raw Output: No output was generated.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karthikr\\AppData\\Local\\Temp\\ipykernel_26700\\1309809254.py:146: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Use to verify factual claims in a piece of text.\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c17e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running comprehensive analysis on paragraph content...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `LengthAndStructureCheck` with `BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  `\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"word_count\": 76, \"sentences\": 7, \"paragraphs\": 1, \"avg_sentence_length\": 10.9, \"issues\": [], \"score\": 10, \"score_explanation\": \"Length & Structure score: 10/10. 76 words, 7 sentences, 1 paragraphs.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FormattingCheck` with `BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  `\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{\"formatting_issues\": [\"Excessive exclamation marks or question marks found.\", \"Some sentences lack proper punctuation.\"], \"caps_ratio\": 0.187, \"score\": 7, \"score_explanation\": \"Formatting score: 7/10. 2 formatting issues detected.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ProfanityCheck` with `BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  `\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m{\"profanity_issues\": [], \"score\": 10, \"score_explanation\": \"Profanity score: 10/10. 0 inappropriate content issues detected.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ClarityCheck` with `BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  `\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check clarity and coherence...\n",
      "\u001b[31;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"clarity_issues\": [\n",
      "        \"Spelling errors (e.g., 'goverment', 'SECRETLEY', 'controll', 'dont', 'CIENTIFICALY', 'frend', 'actualy', 'definatley', 'REPTILIAN', 'babys') obscure the message.\",\n",
      "        \"Excessive use of capital letters and punctuation makes it difficult to discern the main points.\",\n",
      "        \"The message contains vague references (e.g., '5G towers', 'aliens', 'Facebook and Google') without clear explanations.\"\n",
      "    ],\n",
      "    \"coherence_issues\": [\n",
      "        \"The connection between 5G towers and mind control is not logically explained.\",\n",
      "        \"The transition from discussing 5G to aliens running social media lacks a clear rationale.\",\n",
      "        \"The claim about Mark Zuckerberg being a reptilian is presented without supporting evidence or context.\"\n",
      "    ],\n",
      "    \"score\": 2,\n",
      "    \"score_explanation\": \"The text suffers from significant clarity and coherence issues due to numerous spelling errors, excessive capitalization, and a lack of logical flow between ideas. While the overall message is discernible, the chaotic presentation and unsupported claims detract from its effectiveness. The writing style is inconsistent, oscillating between sensationalism and conspiracy theory without a structured argument.\"\n",
      "}\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `GrammarCheck` with `BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  `\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check grammar and language...\n",
      "\u001b[36;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"grammar_errors\": [\n",
      "        \"Incorrect use of 'dont' instead of 'don't'\",\n",
      "        \"Incorrect use of 'controll' instead of 'control'\",\n",
      "        \"Incorrect use of 'actualy' instead of 'actually'\",\n",
      "        \"Incorrect use of 'definatley' instead of 'definitely'\",\n",
      "        \"Incorrect use of 'babys' instead of 'babies'\",\n",
      "        \"Incorrect use of 'CIENTIFICALY' instead of 'scientifically'\"\n",
      "    ],\n",
      "    \"spelling_errors\": [\n",
      "        \"goverment\",\n",
      "        \"SECRETLEY\",\n",
      "        \"controll\",\n",
      "        \"dont\",\n",
      "        \"CIENTIFICALY\",\n",
      "        \"frend\",\n",
      "        \"actualy\",\n",
      "        \"definatley\",\n",
      "        \"babys\"\n",
      "    ],\n",
      "    \"language_issues\": [\n",
      "        \"Use of informal language ('SHEEPLE', 'STUFF') may not be appropriate for a news context\",\n",
      "        \"Overuse of capitalization for emphasis can be seen as unprofessional\",\n",
      "        \"The phrase 'the truth is RIGHT THERE' lacks clarity and specificity\"\n",
      "    ],\n",
      "    \"score\": 2,\n",
      "    \"score_explanation\": \"The text contains numerous spelling and grammar errors, making it difficult to read and understand. The informal language and excessive capitalization detract from the credibility of the message. Overall, the text lacks professionalism and coherence, resulting in a low score.\"\n",
      "}\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `RedundancyCheck` with `BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  `\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{\"redundancy_issues\": [], \"unique_sentence_ratio\": 1.0, \"filler_word_count\": 0, \"score\": 10, \"score_explanation\": \"Redundancy score: 10/10. Unique sentence ratio: 1.0\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `HallucinationCheck` with `BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  `\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check for potential hallucinations...\n",
      "\u001b[38;5;200m\u001b[1;3m{\n",
      "    \"suspicious_claims\": [\n",
      "        \"The government has secretly been using 5G towers to control our minds.\",\n",
      "        \"5G technology is scientifically proven to make us buy more things we don't need.\",\n",
      "        \"Aliens are actually running Facebook and Google to steal our thoughts.\",\n",
      "        \"Mark Zuckerberg is definitely an alien reptilian who eats babies for breakfast.\"\n",
      "    ],\n",
      "    \"contradictions\": [],\n",
      "    \"verification_needed\": [\n",
      "        \"Claims about 5G technology controlling minds.\",\n",
      "        \"Claims about aliens running Facebook and Google.\",\n",
      "        \"Claims about Mark Zuckerberg being an alien reptilian.\"\n",
      "    ],\n",
      "    \"score\": 10,\n",
      "    \"score_explanation\": \"The text contains multiple unfounded conspiracy theories and fantastical claims that lack any credible evidence. The assertions about 5G technology, aliens, and specific individuals being reptilian are not supported by scientific or factual basis, making the overall reliability of the text extremely low.\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': '5G technology mind control'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3m[{'title': 'COVID-19 and 5G conspiracy theories: long term observation of a ...', 'url': 'https://pmc.ncbi.nlm.nih.gov/articles/PMC9137448/', 'content': '3.   The _Mind Control Conspiracy_ assumes that 5G allows some form of mind control and that the COVID-19 or a vaccine against it plants a receiver within humans.\\n\\n4.   Finally, there are some truly _Esoteric Conspiracy Theories_ that see 5G and COVID-19 as means to prevent humans from reaching their full potential or higher selves. [...] Note that _other conspiracy theories_ refers to both older conspiracy theories (or myths) that have been classified previously , as well other misinformation with similar characteristics that appeared in the context of COVID-19, such as that the virus does not exist or was released intentionally, or that the objective of vaccines is mind control. Note however that since we only classify tweets that mention 5G, this does not constitute a general investigation of such misinformation.', 'score': 0.7663815}, {'title': '5G and Mental Health: Is Wireless Technology Messing with Our ...', 'url': 'https://primepsychiatrymd.com/blog/5g-and-mental-health-is-wireless-technology-messing-with-our-minds/', 'content': 'Conspiracy theorists claim that 5G technology can lead to various mental health issues, including anxiety, depression, and even cognitive decline. These claims are often based on the following arguments: [...] ### Conclusion\\n\\nThe debate over 5G technology and its impact on mental health is far from settled. While conspiracy theories and anecdotal reports raise concerns, the scientific evidence does not support the notion that 5G poses a significant risk to mental health. As technology continues to advance, mental health professionals must stay informed and adopt evidence-based practices to enhance patient care. [...] Challenges and Concerns: Conversely, some patients have reported increased anxiety due to the constant connectivity and information overload facilitated by 5G technology. These cases underscore the importance of balanced technology use and the need for mental health professionals to guide patients in managing their tech consumption.', 'score': 0.6599319}, {'title': 'Four experts investigate how the 5G coronavirus conspiracy theory ...', 'url': 'https://theconversation.com/four-experts-investigate-how-the-5g-coronavirus-conspiracy-theory-began-139137', 'content': 'was actually developing a weapon for weather control as well as mind control. Similarly, concerns have been expressed concerning that 5G might be in fact be a hi-tech weapon whose use represents an â€œexistential threat to humanityâ€. [...] The dismissal of the pandemic as a hoax and the questioning of scientific experts is straight out of the playbook of climate change denial. The 5G theory about radiowaves transmitting or activating the virus, for example, is a reworking of long running conspiracy fears about mind control experiments, subliminal messaging and supposed secret US military weapons projects (all ripe topics for Hollywoodâ€™s movie industry).', 'score': 0.6072213}]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "    \"overall_score\": 3,\n",
      "    \"category_scores\": {\n",
      "        \"length_and_structure\": 10,\n",
      "        \"formatting\": 7,\n",
      "        \"profanity\": 10,\n",
      "        \"clarity\": 2,\n",
      "        \"grammar\": 2,\n",
      "        \"redundancy\": 10,\n",
      "        \"hallucinations\": 10\n",
      "    },\n",
      "    \"score_explanations\": {\n",
      "        \"length_and_structure\": \"The text is concise with 76 words, 7 sentences, and 1 paragraph, which is well-structured for a brief news piece.\",\n",
      "        \"formatting\": \"There are some formatting issues, including excessive exclamation marks and inconsistent punctuation.\",\n",
      "        \"profanity\": \"No inappropriate language or profanity was detected.\",\n",
      "        \"clarity\": \"The text suffers from significant clarity issues due to numerous spelling errors, excessive capitalization, and a lack of logical flow between ideas.\",\n",
      "        \"grammar\": \"The text contains multiple spelling and grammar errors, making it difficult to read and understand.\",\n",
      "        \"redundancy\": \"The text is unique with no redundancy or filler content.\",\n",
      "        \"hallucinations\": \"The text contains multiple unfounded conspiracy theories and fantastical claims that lack any credible evidence.\"\n",
      "    },\n",
      "    \"detailed_issues\": {\n",
      "        \"critical_issues\": [\n",
      "            \"Numerous spelling and grammar errors that obscure meaning.\",\n",
      "            \"Unfounded conspiracy theories presented as facts without evidence.\"\n",
      "        ],\n",
      "        \"moderate_issues\": [\n",
      "            \"Excessive use of capitalization and punctuation detracts from professionalism.\",\n",
      "            \"Lack of logical coherence between claims made in the text.\"\n",
      "        ],\n",
      "        \"minor_issues\": [\n",
      "            \"Informal language may not be appropriate for a news context.\"\n",
      "        ]\n",
      "    },\n",
      "    \"summary\": \"The text presents a sensationalist and conspiratorial narrative that is riddled with spelling and grammatical errors, making it difficult to read and understand. To improve the quality, the author should focus on correcting spelling and grammar, reducing excessive punctuation, and providing credible sources for any claims made. Additionally, a more structured argument with logical flow would enhance clarity and coherence.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "âœ… COMPREHENSIVE CONTENT QUALITY REPORT:\n",
      "======================================================================\n",
      "ðŸ† OVERALL QUALITY SCORE: 3 / 10\n",
      "\n",
      "ðŸš¨ CRITICAL ISSUES:\n",
      "   âŒ Numerous spelling and grammar errors that obscure meaning.\n",
      "   âŒ Unfounded conspiracy theories presented as facts without evidence.\n",
      "\n",
      "âš ï¸  MODERATE ISSUES:\n",
      "   âš ï¸  Excessive use of capitalization and punctuation detracts from professionalism.\n",
      "   âš ï¸  Lack of logical coherence between claims made in the text.\n",
      "\n",
      "ðŸ’¡ MINOR ISSUES:\n",
      "   ðŸ’¡ Informal language may not be appropriate for a news context.\n",
      "\n",
      "--- DETAILED CATEGORY BREAKDOWN ---\n",
      "\n",
      "ðŸŸ¢ Length & Structure: 10/10\n",
      "   â””â”€ The text is concise with 76 words, 7 sentences, and 1 paragraph, which is well-structured for a brief news piece.\n",
      "\n",
      "ðŸŸ¡ Formatting: 7/10\n",
      "   â””â”€ There are some formatting issues, including excessive exclamation marks and inconsistent punctuation.\n",
      "\n",
      "ðŸŸ¢ Profanity & Appropriateness: 10/10\n",
      "   â””â”€ No inappropriate language or profanity was detected.\n",
      "\n",
      "ðŸ”´ Clarity & Coherence: 2/10\n",
      "   â””â”€ The text suffers from significant clarity issues due to numerous spelling errors, excessive capitalization, and a lack of logical flow between ideas.\n",
      "\n",
      "ðŸ”´ Grammar & Language: 2/10\n",
      "   â””â”€ The text contains multiple spelling and grammar errors, making it difficult to read and understand.\n",
      "\n",
      "ðŸŸ¢ Redundancy & Repetition: 10/10\n",
      "   â””â”€ The text is unique with no redundancy or filler content.\n",
      "\n",
      "ðŸŸ¢ Accuracy & Hallucinations: 10/10\n",
      "   â””â”€ The text contains multiple unfounded conspiracy theories and fantastical claims that lack any credible evidence.\n",
      "\n",
      "--- SUMMARY & RECOMMENDATIONS ---\n",
      "The text presents a sensationalist and conspiratorial narrative that is riddled with spelling and grammatical errors, making it difficult to read and understand. To improve the quality, the author should focus on correcting spelling and grammar, reducing excessive punctuation, and providing credible sources for any claims made. Additionally, a more structured argument with logical flow would enhance clarity and coherence.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs, sentences).\"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    \n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    # Length checks\n",
    "    if word_count < 50:\n",
    "        issues.append(f\"Content is too short with only {word_count} words.\")\n",
    "        score -= 3\n",
    "    elif word_count > 1000:\n",
    "        issues.append(f\"Content is very long with {word_count} words. Consider breaking into sections.\")\n",
    "        score -= 1\n",
    "    \n",
    "    # Structure checks\n",
    "    if word_count > 200 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content should be broken into multiple paragraphs for better readability.\")\n",
    "        score -= 2\n",
    "    \n",
    "    if len(sentences) < 3 and word_count > 50:\n",
    "        issues.append(\"Content has very few sentences; consider adding more detail.\")\n",
    "        score -= 2\n",
    "    \n",
    "    # Sentence length checks\n",
    "    avg_sentence_length = word_count / max(1, len(sentences))\n",
    "    if avg_sentence_length > 25:\n",
    "        issues.append(\"Average sentence length is too long; consider shorter sentences.\")\n",
    "        score -= 1\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"word_count\": word_count,\n",
    "        \"sentences\": len(sentences),\n",
    "        \"paragraphs\": len(paragraphs),\n",
    "        \"avg_sentence_length\": round(avg_sentence_length, 1),\n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Length & Structure score: {max(1, score)}/10. {word_count} words, {len(sentences)} sentences, {len(paragraphs)} paragraphs.\"\n",
    "    })\n",
    "\n",
    "def check_formatting_and_presentation(text: str) -> str:\n",
    "    \"\"\"Checks formatting, presentation, and visual structure.\"\"\"\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    # Check for excessive punctuation\n",
    "    if re.search(r'[!?]{3,}', text):\n",
    "        issues.append(\"Excessive exclamation marks or question marks found.\")\n",
    "        score -= 2\n",
    "    \n",
    "    # Check for all caps (shouting)\n",
    "    caps_ratio = sum(1 for c in text if c.isupper()) / max(1, len(text))\n",
    "    if caps_ratio > 0.3:\n",
    "        issues.append(\"Excessive use of capital letters appears unprofessional.\")\n",
    "        score -= 3\n",
    "    \n",
    "    # Check for inconsistent spacing\n",
    "    if re.search(r'\\s{3,}', text):\n",
    "        issues.append(\"Inconsistent spacing found (multiple spaces).\")\n",
    "        score -= 1\n",
    "    \n",
    "    # Check for proper sentence endings\n",
    "    sentences_without_proper_ending = len([s for s in re.split(r'[.!?]+', text) if s.strip() and not re.search(r'[.!?]\\s*$', s)])\n",
    "    if sentences_without_proper_ending > len(text.split('.')) * 0.2:\n",
    "        issues.append(\"Some sentences lack proper punctuation.\")\n",
    "        score -= 1\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"formatting_issues\": issues,\n",
    "        \"caps_ratio\": round(caps_ratio, 3),\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Formatting score: {max(1, score)}/10. {len(issues)} formatting issues detected.\"\n",
    "    })\n",
    "\n",
    "def check_profanity_and_appropriateness(text: str) -> str:\n",
    "    \"\"\"Checks for profanity and inappropriate content.\"\"\"\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    # Extended profanity list\n",
    "    profanity_patterns = [\n",
    "        r'\\b(fuck|shit|damn|bitch|asshole|bastard|crap|hell)\\b',\n",
    "        r'\\b(stupid|idiot|moron|retard)\\b',  # Potentially offensive terms\n",
    "    ]\n",
    "    \n",
    "    for pattern in profanity_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            issues.append(\"Inappropriate or potentially offensive language detected.\")\n",
    "            score -= 4\n",
    "            break\n",
    "    \n",
    "    # Check for discriminatory language\n",
    "    discriminatory_patterns = [\n",
    "        r'\\b(hate|discrimination|racist|sexist)\\b'\n",
    "    ]\n",
    "    \n",
    "    for pattern in discriminatory_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            issues.append(\"Potentially discriminatory language detected.\")\n",
    "            score -= 3\n",
    "            break\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"profanity_issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Profanity score: {max(1, score)}/10. {len(issues)} inappropriate content issues detected.\"\n",
    "    })\n",
    "\n",
    "def check_clarity_and_coherence(text: str) -> str:\n",
    "    \"\"\"Uses LLM to check for clarity, coherence, and logical flow.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check clarity and coherence...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert writing analyst. Evaluate the following text for clarity and coherence:\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \n",
    "    Analyze:\n",
    "    1. Clarity: Is the message clear and easy to understand?\n",
    "    2. Coherence: Do ideas flow logically from one to another?\n",
    "    3. Consistency: Is the writing style and tone consistent?\n",
    "    4. Organization: Is the content well-organized?\n",
    "    \n",
    "    Respond with a JSON object:\n",
    "    {{\n",
    "        \"clarity_issues\": [\"list of clarity problems\"],\n",
    "        \"coherence_issues\": [\"list of logical flow problems\"], \n",
    "        \"score\": <integer 1-10>,\n",
    "        \"score_explanation\": \"<detailed explanation of score>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_grammar_and_language(text: str) -> str:\n",
    "    \"\"\"Uses LLM to check for grammar, spelling, and language quality.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar and language...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader and grammar checker. Analyze the following text:\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \n",
    "    Check for:\n",
    "    1. Grammar mistakes\n",
    "    2. Spelling errors\n",
    "    3. Punctuation issues\n",
    "    4. Word choice and vocabulary appropriateness\n",
    "    5. Sentence structure problems\n",
    "    \n",
    "    Respond with a JSON object:\n",
    "    {{\n",
    "        \"grammar_errors\": [\"list of grammar issues\"],\n",
    "        \"spelling_errors\": [\"list of spelling mistakes\"],\n",
    "        \"language_issues\": [\"list of language/vocabulary issues\"],\n",
    "        \"score\": <integer 1-10>,\n",
    "        \"score_explanation\": \"<detailed explanation of score>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_redundancy_and_repetition(text: str) -> str:\n",
    "    \"\"\"Analyzes text for redundancy, repetition, and verbose content.\"\"\"\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    # Check sentence redundancy\n",
    "    if len(sentences) > 3:\n",
    "        unique_sentences = len(set(sentences))\n",
    "        redundancy_ratio = unique_sentences / len(sentences)\n",
    "        if redundancy_ratio < 0.7:\n",
    "            redundancy_percentage = (1 - redundancy_ratio) * 100\n",
    "            issues.append(f\"High sentence redundancy: {redundancy_percentage:.0f}% of sentences are repetitive.\")\n",
    "            score -= 3\n",
    "    \n",
    "    # Check word repetition\n",
    "    if len(words) > 20:\n",
    "        word_freq = {}\n",
    "        for word in words:\n",
    "            if len(word) > 4:  # Only check longer words\n",
    "                word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        \n",
    "        overused_words = [(word, count) for word, count in word_freq.items() if count > len(words) * 0.05]\n",
    "        if overused_words:\n",
    "            issues.append(f\"Overused words detected: {[f'{word}({count})' for word, count in overused_words[:3]]}\")\n",
    "            score -= 2\n",
    "    \n",
    "    # Check for filler words\n",
    "    filler_words = ['very', 'really', 'quite', 'rather', 'pretty', 'somewhat', 'actually']\n",
    "    filler_count = sum(1 for word in words if word in filler_words)\n",
    "    if filler_count > len(words) * 0.03:\n",
    "        issues.append(f\"Excessive use of filler words: {filler_count} instances.\")\n",
    "        score -= 1\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"redundancy_issues\": issues,\n",
    "        \"unique_sentence_ratio\": round(len(set(sentences)) / max(1, len(sentences)), 2),\n",
    "        \"filler_word_count\": filler_count,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Redundancy score: {max(1, score)}/10. Unique sentence ratio: {round(len(set(sentences)) / max(1, len(sentences)), 2)}\"\n",
    "    })\n",
    "\n",
    "def check_hallucinations_and_accuracy(text: str) -> str:\n",
    "    \"\"\"Uses LLM and fact-checking to detect potential hallucinations and inaccuracies.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check for potential hallucinations...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert fact-checker. Analyze the following text for potential hallucinations and inaccuracies:\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \n",
    "    Look for:\n",
    "    1. Factual claims that seem suspicious or incorrect\n",
    "    2. Contradictory statements within the text\n",
    "    3. Unrealistic or impossible scenarios\n",
    "    4. Inconsistent information\n",
    "    5. Claims that need verification\n",
    "    \n",
    "    Respond with a JSON object:\n",
    "    {{\n",
    "        \"suspicious_claims\": [\"list of potentially false or unverifiable claims\"],\n",
    "        \"contradictions\": [\"list of contradictory statements\"],\n",
    "        \"verification_needed\": [\"list of claims that should be fact-checked\"],\n",
    "        \"score\": <integer 1-10>,\n",
    "        \"score_explanation\": \"<detailed explanation of score>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# ==============================================================================\n",
    "#  AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "            Tool(name=\"LengthAndStructureCheck\", func=check_length_and_structure, description=\"Check word count, sentence count, paragraph structure, and overall organization.\"),\n",
    "            Tool(name=\"FormattingCheck\", func=check_formatting_and_presentation, description=\"Check formatting, presentation, and visual structure issues.\"),\n",
    "            Tool(name=\"ProfanityCheck\", func=check_profanity_and_appropriateness, description=\"Check for profanity, inappropriate language, and offensive content.\"),\n",
    "            Tool(name=\"ClarityCheck\", func=check_clarity_and_coherence, description=\"Check for clarity, coherence, logical flow, and organization.\"),\n",
    "            Tool(name=\"GrammarCheck\", func=check_grammar_and_language, description=\"Check grammar, spelling, punctuation, and language quality.\"),\n",
    "            Tool(name=\"RedundancyCheck\", func=check_redundancy_and_repetition, description=\"Check for redundancy, repetition, and verbose content.\"),\n",
    "            Tool(name=\"HallucinationCheck\", func=check_hallucinations_and_accuracy, description=\"Check for potential hallucinations, inaccuracies, and contradictions.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Verify factual claims and statements.\")\n",
    "        ]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Content Quality Analyst. Your goal is to provide a comprehensive quality assessment of text content.\n",
    "\n",
    "            **Your Analysis Plan:**\n",
    "            1. Run ALL available checks on the provided text\n",
    "            2. Use the LengthAndStructureCheck for length and structure analysis\n",
    "            3. Use the FormattingCheck for formatting and presentation\n",
    "            4. Use the ProfanityCheck for appropriateness and profanity\n",
    "            5. Use the ClarityCheck for clarity and coherence\n",
    "            6. Use the GrammarCheck for grammar and language quality\n",
    "            7. Use the RedundancyCheck for redundancy and repetition\n",
    "            8. Use the HallucinationCheck for accuracy and potential hallucinations\n",
    "            9. Use FactCheckSearch if you find specific factual claims that need verification\n",
    "            \n",
    "            **FINAL ANSWER FORMATTING:**\n",
    "            Your final answer MUST be a single JSON object with this exact structure:\n",
    "            {{\n",
    "                \"overall_score\": <integer 1-10>,\n",
    "                \"category_scores\": {{\n",
    "                    \"length_and_structure\": <score 1-10>,\n",
    "                    \"formatting\": <score 1-10>,\n",
    "                    \"profanity\": <score 1-10>,\n",
    "                    \"clarity\": <score 1-10>,\n",
    "                    \"grammar\": <score 1-10>,\n",
    "                    \"redundancy\": <score 1-10>,\n",
    "                    \"hallucinations\": <score 1-10>\n",
    "                }},\n",
    "                \"score_explanations\": {{\n",
    "                    \"length_and_structure\": \"<explanation>\",\n",
    "                    \"formatting\": \"<explanation>\",\n",
    "                    \"profanity\": \"<explanation>\",\n",
    "                    \"clarity\": \"<explanation>\",\n",
    "                    \"grammar\": \"<explanation>\",\n",
    "                    \"redundancy\": \"<explanation>\",\n",
    "                    \"hallucinations\": \"<explanation>\"\n",
    "                }},\n",
    "                \"detailed_issues\": {{\n",
    "                    \"critical_issues\": [\"list of critical problems\"],\n",
    "                    \"moderate_issues\": [\"list of moderate problems\"],\n",
    "                    \"minor_issues\": [\"list of minor problems\"]\n",
    "                }},\n",
    "                \"summary\": \"<comprehensive summary with specific suggestions for improvement>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def validate_async(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Runs comprehensive content quality analysis on the provided text.\"\"\"\n",
    "        \n",
    "        prompt = f\"Please provide a comprehensive quality analysis of the following text content:\\n---\\n{text}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            # Use regex to find the JSON object in case the LLM adds extra text\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: API keys must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "    \n",
    "    # --- CASE 2: Large Paragraph Analysis ---\n",
    "    large_paragraph = \"\"\"\n",
    "    BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()  \"\"\"\n",
    "    \n",
    "    print(\"\\n\\nðŸ” Running comprehensive analysis on paragraph content...\")\n",
    "    print(\"=\" * 60)\n",
    "    report = await validator.validate_async(large_paragraph)\n",
    "    print_report(report)\n",
    "\n",
    "\n",
    "\n",
    "def print_report(report: Dict[str, Any]):\n",
    "    \"\"\"Helper function to neatly print the agent's report.\"\"\"\n",
    "    print(\"\\nâœ… COMPREHENSIVE CONTENT QUALITY REPORT:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"âŒ An error occurred: {report['error']}\")\n",
    "        print(f\"Raw Output: {report.get('raw_output')}\")\n",
    "    else:\n",
    "        print(f\"ðŸ† OVERALL QUALITY SCORE: {report.get('overall_score', 'N/A')} / 10\")\n",
    "        \n",
    "        # Display detailed issues\n",
    "        detailed_issues = report.get('detailed_issues', {})\n",
    "        if detailed_issues.get('critical_issues'):\n",
    "            print(\"\\nðŸš¨ CRITICAL ISSUES:\")\n",
    "            for issue in detailed_issues['critical_issues']:\n",
    "                print(f\"   âŒ {issue}\")\n",
    "        \n",
    "        if detailed_issues.get('moderate_issues'):\n",
    "            print(\"\\nâš ï¸  MODERATE ISSUES:\")\n",
    "            for issue in detailed_issues['moderate_issues']:\n",
    "                print(f\"   âš ï¸  {issue}\")\n",
    "        \n",
    "        if detailed_issues.get('minor_issues'):\n",
    "            print(\"\\nðŸ’¡ MINOR ISSUES:\")\n",
    "            for issue in detailed_issues['minor_issues']:\n",
    "                print(f\"   ðŸ’¡ {issue}\")\n",
    "        \n",
    "        print(\"\\n--- DETAILED CATEGORY BREAKDOWN ---\")\n",
    "        category_scores = report.get('category_scores', {})\n",
    "        score_explanations = report.get('score_explanations', {})\n",
    "        \n",
    "        categories = [\n",
    "            ('length_and_structure', 'Length & Structure'),\n",
    "            ('formatting', 'Formatting'),\n",
    "            ('profanity', 'Profanity & Appropriateness'),\n",
    "            ('clarity', 'Clarity & Coherence'),\n",
    "            ('grammar', 'Grammar & Language'),\n",
    "            ('redundancy', 'Redundancy & Repetition'),\n",
    "            ('hallucinations', 'Accuracy & Hallucinations')\n",
    "        ]\n",
    "        \n",
    "        for category_key, category_name in categories:\n",
    "            score = category_scores.get(category_key, 'N/A')\n",
    "            explanation = score_explanations.get(category_key, \"No explanation provided.\")\n",
    "            \n",
    "            # Add emoji based on score\n",
    "            if isinstance(score, int):\n",
    "                if score >= 9:\n",
    "                    emoji = \"ðŸŸ¢\"\n",
    "                elif score >= 7:\n",
    "                    emoji = \"ðŸŸ¡\"\n",
    "                elif score >= 5:\n",
    "                    emoji = \"ðŸŸ \"\n",
    "                else:\n",
    "                    emoji = \"ðŸ”´\"\n",
    "            else:\n",
    "                emoji = \"âšª\"\n",
    "            \n",
    "            print(f\"\\n{emoji} {category_name}: {score}/10\")\n",
    "            print(f\"   â””â”€ {explanation}\")\n",
    "        \n",
    "        print(f\"\\n--- SUMMARY & RECOMMENDATIONS ---\")\n",
    "        print(report.get('summary', 'No summary provided.'))\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Run the main async function\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbcfde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running analysis on Plain Text Input...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `GrammarAndSpellingCheck` with `Data analysis is important. Data analysis helps businesses. Businesses use data analysis. Data analysis is used by businesses to analyze data. Analyzing data is what data analysis does. Data analysis analyzes data for businesses. Businesses need data analysis to analyze their data. Data analysis is the analysis of data. Data is analyzed through data analysis. Data analysis is important for data.`\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check grammar...\n",
      "\u001b[33;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"errors\": [\n",
      "    \"Repetitive use of 'data analysis' and 'data' makes the text redundant.\",\n",
      "    \"Lack of variety in sentence structure leads to monotony.\"\n",
      "  ],\n",
      "  \"score\": 6,\n",
      "  \"score_explanation\": \"The text is grammatically correct and free of spelling mistakes, but it suffers from excessive repetition and lack of variety in sentence structure, which detracts from its overall quality.\"\n",
      "}\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ReadabilityCheck` with `Data analysis is important. Data analysis helps businesses. Businesses use data analysis. Data analysis is used by businesses to analyze data. Analyzing data is what data analysis does. Data analysis analyzes data for businesses. Businesses need data analysis to analyze their data. Data analysis is the analysis of data. Data is analyzed through data analysis. Data analysis is important for data.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m{\"flesch_reading_ease_score\": 10.640221311475443, \"level\": \"Very Confusing (College Graduate)\", \"readability_score\": 3, \"score_explanation\": \"Readability score: 3/10. Flesch score of 10.6 indicates very confusing (college graduate) reading level.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ProfessionalismCheck` with `Data analysis is important. Data analysis helps businesses. Businesses use data analysis. Data analysis is used by businesses to analyze data. Analyzing data is what data analysis does. Data analysis analyzes data for businesses. Businesses need data analysis to analyze their data. Data analysis is the analysis of data. Data is analyzed through data analysis. Data analysis is important for data.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3m{\"issues\": [], \"score\": 10, \"score_explanation\": \"Professionalism score: 10/10. 0 professional issues detected.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `RedundancyCheck` with `Data analysis is important. Data analysis helps businesses. Businesses use data analysis. Data analysis is used by businesses to analyze data. Analyzing data is what data analysis does. Data analysis analyzes data for businesses. Businesses need data analysis to analyze their data. Data analysis is the analysis of data. Data is analyzed through data analysis. Data analysis is important for data.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{\"redundancy_issues\": [], \"score\": 10, \"score_explanation\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': 'Data analysis is important for businesses.'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'title': 'Why is Data Analysis Important for Businesses', 'url': 'https://www.alliant.edu/blog/why-is-data-analysis-important', 'content': 'Successful businesses may rely on human intuition, but data analysis is an enormous, indispensable component of their success. By examining non-biased, raw data, they can make informed decisions that will benefit their companyâ€”and ensure their viability as time progresses.1\\n\\nBut why is data analysis important? And what are the advantages of learning more about data analytics and data science on your academic and professional journey? [...] Data analytics helps companies evaluate their competitorsâ€™ performance, price points, marketing methods, social media reach, and more. Business leaders can make informed decisions to ensure theyâ€™re taking the proper, proactive steps to remain at the top of their niche.\\n\\n## Additional Benefits of Data Analytics\\n\\nData analytics is an invaluable tool for businesses. In addition to the benefits outlined above, it may enhance: [...] One of the most significant benefits of data analytics is that it takes speculation out of critical (and even minor) business decisions. Historical data provides valuable insight that enables businesses to assess where they presently stand, predict future outcomes, and pinpointâ€”and mitigateâ€”risks.\\n\\n### #2. Operational Efficiency and Process Improvement', 'score': 0.9161773}, {'title': 'The Importance of Data Analytics in Business | P.I.T.', 'url': 'https://www.pit.edu/news/the-importance-of-data-analytics-in-business/', 'content': '## 5 Reasons Why Data Analytics Skills Are Imperative for Business\\n\\nSimply put, companies in the corporate world operate in such a fast-paced and competitive environment that, in order stay ahead, they need people at every level who can interpret data and turn that data into strategies, actions, and results.\\n\\nKey reasons why data analytics is so important to many organizations include the following.\\n\\n### 1. Better Decision Making [...] Across every industry, employers need professionals who can do more than just manage operations â€“ they need people who can interpret data and turn it into action. Especially in the business world, the ability to understand and apply data is becoming more and more essential for success at every level of your career. This growing demand is why data analytics is such an important focus in business today. Read on to learn how data analytics skills can help support your career and lead to', 'score': 0.8812988}, {'title': 'How does data analysis influence business decision making? - Sage', 'url': 'https://www.sage.com/en-us/blog/how-does-data-analysis-influence-business-decision-making/', 'content': 'In todayâ€™s fast-paced business environment, data analysis has become an indispensable tool, equipping companies with the power to make informed decisions that drive success and innovation.\\n\\nIn this landscape, the difference between a business thriving and merely surviving often hinges on the ability to analyze vast quantities of data.\\n\\nFrom startups to multinational corporations, the adoption of data analytics is no longer a luxury but a necessity. [...] As the landscape of business continues to evolve, the role of data analysis in decision-making will undoubtedly grow, paving the way for new levels of success and discovery.\\n\\nIn embracing the future of data-driven decision-making, businesses must also be vigilant of the potential pitfalls.\\n\\nMisinterpretation of data, overreliance on numerical insights, and the risks of data privacy breaches are just a few of the challenges that need careful navigation. [...] Whether itâ€™s optimizing supply chains, personalizing marketing strategies, improving customer service, or innovating product development, data analysis provides a multidimensional view of business operations.\\n\\nIn a world where data holds the key to efficiency and innovation, embracing this approach means embracing a future of informed, bold steps forward.', 'score': 0.8795718}]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "    \"overall_score\": 5,\n",
      "    \"category_scores\": {\n",
      "        \"grammar_and_spelling\": 6,\n",
      "        \"readability\": 3,\n",
      "        \"professionalism_and_tone\": 10,\n",
      "        \"factual_accuracy\": 10,\n",
      "        \"redundancy\": 10,\n",
      "        \"faithfulness\": 10\n",
      "    },\n",
      "    \"score_explanations\": {\n",
      "        \"grammar_and_spelling\": \"The text is grammatically correct and free of spelling mistakes, but it suffers from excessive repetition and lack of variety in sentence structure, which detracts from its overall quality.\",\n",
      "        \"readability\": \"Readability score: 3/10. Flesch score of 10.6 indicates very confusing (college graduate) reading level.\",\n",
      "        \"professionalism_and_tone\": \"Professionalism score: 10/10. 0 professional issues detected.\",\n",
      "        \"factual_accuracy\": \"The claims about the importance of data analysis for businesses are accurate and supported by multiple sources.\",\n",
      "        \"redundancy\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00.\",\n",
      "        \"faithfulness\": \"N/A for plain text.\"\n",
      "    },\n",
      "    \"contextual_errors\": [],\n",
      "    \"summary\": \"The text discusses the importance of data analysis for businesses but suffers from significant redundancy and lack of variety in sentence structure, leading to a low readability score. While the content is factually accurate and maintains a professional tone, the excessive repetition of phrases makes it confusing and monotonous. To improve, consider varying sentence structure and reducing redundancy to enhance clarity and engagement.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "âœ… FINAL AGENT REPORT:\n",
      "------------------------------------------------------------\n",
      "ðŸ† Overall Quality Score: 5 / 10\n",
      "\n",
      "--- Category Breakdown ---\n",
      "   - Grammar And Spelling: 6/10\n",
      "     â””â”€ The text is grammatically correct and free of spelling mistakes, but it suffers from excessive repetition and lack of variety in sentence structure, which detracts from its overall quality.\n",
      "   - Readability: 3/10\n",
      "     â””â”€ Readability score: 3/10. Flesch score of 10.6 indicates very confusing (college graduate) reading level.\n",
      "   - Professionalism And Tone: 10/10\n",
      "     â””â”€ Professionalism score: 10/10. 0 professional issues detected.\n",
      "   - Factual Accuracy: 10/10\n",
      "     â””â”€ The claims about the importance of data analysis for businesses are accurate and supported by multiple sources.\n",
      "   - Redundancy: 10/10\n",
      "     â””â”€ Redundancy score: 10/10. Unique sentence ratio: 1.00.\n",
      "   - Faithfulness: 10/10\n",
      "     â””â”€ N/A for plain text.\n",
      "\n",
      "--- Summary & Suggestions ---\n",
      "The text discusses the importance of data analysis for businesses but suffers from significant redundancy and lack of variety in sentence structure, leading to a low readability score. While the content is factually accurate and maintains a professional tone, the excessive repetition of phrases makes it confusing and monotonous. To improve, consider varying sentence structure and reducing redundancy to enhance clarity and engagement.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "        score -= 3\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "        score -= 2\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"word_count\": word_count, \n",
    "        \"sentences\": len(sentences), \n",
    "        \"paragraphs\": len(paragraphs), \n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Structure score: {max(1, score)}/10. Based on {word_count} words, {len(sentences)} sentences, {len(paragraphs)} paragraphs.\"\n",
    "    })\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond with a JSON object with:\n",
    "    - \"errors\": [\"list of concise error descriptions\"]\n",
    "    - \"score\": integer from 1-10 (10 = perfect, deduct points for each error)\n",
    "    - \"score_explanation\": brief explanation of why this score was given\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_readability_with_textstat(text: str) -> str:\n",
    "    \"\"\"Uses the 'textstat' library to calculate objective readability scores.\"\"\"\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\", \"readability_score\": 1, \"score_explanation\": \"Cannot assess readability of empty text.\"})\n",
    "    \n",
    "    flesch_score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    readability_score = 10\n",
    "    \n",
    "    if flesch_score < 30: \n",
    "        level = \"Very Confusing (College Graduate)\"\n",
    "        readability_score = 3\n",
    "    elif flesch_score < 60: \n",
    "        level = \"Difficult\"\n",
    "        readability_score = 6\n",
    "    elif flesch_score < 80: \n",
    "        level = \"Fairly Easy\"\n",
    "        readability_score = 8\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"flesch_reading_ease_score\": flesch_score, \n",
    "        \"level\": level,\n",
    "        \"readability_score\": readability_score,\n",
    "        \"score_explanation\": f\"Readability score: {readability_score}/10. Flesch score of {flesch_score:.1f} indicates {level.lower()} reading level.\"\n",
    "    })\n",
    "\n",
    "def check_professionalism(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content like profanity, slang, or excessive formatting.\"\"\"\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "        score -= 5\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "        score -= 3\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Professionalism score: {max(1, score)}/10. {len(issues)} professional issues detected.\"\n",
    "    })\n",
    "\n",
    "def check_redundancy(text: str) -> str:\n",
    "    \"\"\"Analyzes the text for repetitive sentences and overused words.\"\"\"\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if len(sentences) > 2:\n",
    "        redundancy_ratio = len(set(sentences)) / len(sentences)\n",
    "        if redundancy_ratio < 0.5:\n",
    "            redundancy_percentage = 100 - redundancy_ratio*100\n",
    "            issues.append(f\"High sentence redundancy detected. {redundancy_percentage:.0f}% of sentences are repetitive.\")\n",
    "            score = max(1, int(redundancy_ratio * 10))\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"redundancy_issues\": issues,\n",
    "        \"score\": score,\n",
    "        \"score_explanation\": f\"Redundancy score: {score}/10. Unique sentence ratio: {(len(set(sentences)) / max(1, len(sentences))):.2f}\"\n",
    "    })\n",
    "\n",
    "def check_itext_payload_faithfulness(payload_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes an iText JSON payload. It checks for:\n",
    "    1. Contextual relevance between message and content\n",
    "    2. Consistency between the message and data\n",
    "    3. Faithfulness and relevance between the 'content', 'simplified', and 'elaborated' versions.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Using LLM to analyze iText payload...\")\n",
    "    try:\n",
    "        payload = json.loads(payload_str)\n",
    "        message = payload.get(\"message\", \"\")\n",
    "        content_data = payload.get(\"data\", [{}])[0].get(\"data\", {})\n",
    "        original = content_data.get(\"content\", \"\")\n",
    "        simplified = content_data.get(\"simplified\", \"\")\n",
    "        elaborated = content_data.get(\"elaborated\", \"\")\n",
    "    except (json.JSONDecodeError, IndexError, KeyError) as e:\n",
    "        return json.dumps({\"error\": f\"Invalid iText payload structure: {e}\"})\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert iText payload evaluator. Analyze the following payload for contextual relevance and faithfulness:\n",
    "    \n",
    "    Message: \"{message}\"\n",
    "    Original Content: \"{original}\"\n",
    "    Simplified Content: \"{simplified}\"\n",
    "    Elaborated Content: \"{elaborated}\"\n",
    "\n",
    "    Evaluate these aspects:\n",
    "    \n",
    "    1. **Message-Content Relevance**: Does the content actually relate to what the message indicates? \n",
    "       For example, if message mentions \"data science\" but content is about \"astronomy\", this is a MAJOR ERROR.\n",
    "    \n",
    "    2. **Content Consistency**: Are all three versions (original, simplified, elaborated) about the same topic?\n",
    "    \n",
    "    3. **Faithfulness**: Do simplified/elaborated versions maintain the original meaning without adding incorrect information?\n",
    "    \n",
    "    4. **Success Message Validation**: If the message indicates \"success\", does the content seem properly generated?\n",
    "\n",
    "    Return ONLY a JSON object with your findings:\n",
    "    {{\n",
    "        \"message_content_relevance\": <int 1-10>,\n",
    "        \"content_consistency\": <int 1-10>,\n",
    "        \"faithfulness_score\": <int 1-10>,\n",
    "        \"overall_faithfulness_score\": <int 1-10>,\n",
    "        \"contextual_errors\": [\"list of specific contextual mismatches found\"],\n",
    "        \"faithfulness_issues\": [\"list of faithfulness problems between versions\"],\n",
    "        \"score_explanation\": \"<Detailed explanation covering all aspects>\",\n",
    "        \"critical_error\": <boolean - true if major contextual mismatch exists>\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# ==============================================================================\n",
    "#  AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "            Tool(name=\"iTextPayloadFaithfulnessCheck\", func=check_itext_payload_faithfulness, description=\"Use this ONLY for a JSON input representing an iText payload. It checks contextual relevance between message and content, and faithfulness between content versions.\"),\n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism, description=\"Use to check a piece of text for unprofessional language.\"),\n",
    "            Tool(name=\"LengthAndStructureCheck\", func=check_length_and_structure, description=\"Use to get word count and structure of a piece of text.\"),\n",
    "            Tool(name=\"RedundancyCheck\", func=check_redundancy, description=\"Use to check a piece of text for repetitive sentences.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Use to verify factual claims in a piece of text.\")\n",
    "        ]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Quality Assurance assistant. Your goal is to provide a complete quality report.\n",
    "\n",
    "            You will receive one of two types of input:\n",
    "            1.  A plain text paragraph.\n",
    "            2.  A JSON string representing an \"iText payload\".\n",
    "\n",
    "            **Your Plan:**\n",
    "            - If the input is an iText payload (JSON), you MUST use the `iTextPayloadFaithfulnessCheck` tool on the entire JSON. You should ALSO run standard checks (grammar, professionalism, etc.) on the 'content' field within the payload.\n",
    "            - If the input is plain text, just run the standard checks on it.\n",
    "            \n",
    "            **CRITICAL**: For iText payloads, pay special attention to contextual relevance between the message and content. If there's a major mismatch (e.g., message about \"data science\" but content about \"astronomy\"), this should significantly impact the overall score and be prominently mentioned in the summary.\n",
    "            \n",
    "            After executing your plan, compile all results into the final JSON report.\n",
    "\n",
    "            **FINAL ANSWER FORMATTING INSTRUCTIONS:**\n",
    "            Your final answer MUST be a single JSON object with the specified structure.\n",
    "            {{\n",
    "                \"overall_score\": <An integer score from 1-10>,\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <Score 1-10>,\n",
    "                    \"readability\": <Score 1-10>,\n",
    "                    \"professionalism_and_tone\": <Score 1-10>,\n",
    "                    \"factual_accuracy\": <Score 1-10. Default to 10 if no claims to check.>,\n",
    "                    \"redundancy\": <Score 1-10>,\n",
    "                    \"faithfulness\": <Score 1-10. Only applies to iText. Default to 10 for plain text.>\n",
    "                }},\n",
    "                \"score_explanations\": {{\n",
    "                    \"grammar_and_spelling\": \"<Explanation for grammar score>\",\n",
    "                    \"readability\": \"<Explanation for readability score>\",\n",
    "                    \"professionalism_and_tone\": \"<Explanation for professionalism score>\",\n",
    "                    \"factual_accuracy\": \"<Explanation for factual accuracy score>\",\n",
    "                    \"redundancy\": \"<Explanation for redundancy score>\",\n",
    "                    \"faithfulness\": \"<Explanation for faithfulness score including contextual relevance>\"\n",
    "                }},\n",
    "                \"contextual_errors\": [\"<List of contextual mismatches between message and content>\"],\n",
    "                \"summary\": \"<A natural language summary of key issues and suggestions for improvement. PROMINENTLY mention any contextual errors.>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def validate_async(self, input_data: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent asynchronously on either a string or a dictionary.\"\"\"\n",
    "        \n",
    "        if isinstance(input_data, dict):\n",
    "            # It's an iText payload, serialize it to a string for the agent\n",
    "            input_str = json.dumps(input_data, indent=2)\n",
    "            analysis_subject = \"the following iText payload\"\n",
    "        else:\n",
    "            # It's a plain paragraph\n",
    "            input_str = input_data\n",
    "            analysis_subject = \"the following text\"\n",
    "            \n",
    "        prompt = f\"Please provide a comprehensive quality analysis of {analysis_subject}:\\n---\\n{input_str}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            # Use regex to find the JSON object in case the LLM adds extra text\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: API keys must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "\n",
    "    # --- CASE 1: Plain Text Input ---\n",
    "    text_input = \"\"\"\n",
    "Data analysis is important. Data analysis helps businesses. Businesses use data analysis. Data analysis is used by businesses to analyze data. Analyzing data is what data analysis does. Data analysis analyzes data for businesses. Businesses need data analysis to analyze their data. Data analysis is the analysis of data. Data is analyzed through data analysis. Data analysis is important for data.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\nðŸ” Running analysis on Plain Text Input...\")\n",
    "    print(\"=\" * 60)\n",
    "    report1 = await validator.validate_async(text_input)\n",
    "    print_report(report1)\n",
    "\n",
    "    # # --- CASE 2: iText Payload with CONTEXTUAL MISMATCH ---\n",
    "    # itext_payload = {\n",
    "    #     \"message\": \"Successfully generated data science content\",\n",
    "    #     \"data\": [\n",
    "    #         {\n",
    "    #             \"type\": \"iText\",\n",
    "    #             \"data\": {\n",
    "    #                 \"content\": \"The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.\",\n",
    "    #                 \"simplified\": \"The sun is a big star in the middle of our solar system.\",\n",
    "    #                 \"elaborated\": \"The Sun, a G-type main-sequence star (G2V), is the focal point of our Solar System. Comprising over 99.8% of the system's mass, it is an immense sphere of incandescent plasma, with a diameter of approximately 1.39 million kilometers, roughly 109 times that of our planet.\"\n",
    "    #             }\n",
    "    #         }\n",
    "    #     ]\n",
    "    # }\n",
    "    # print(\"\\n\\nðŸ” Running analysis on iText Payload...\")\n",
    "    # print(\"=\" * 60)\n",
    "    # report2 = await validator.validate_async(itext_payload)\n",
    "    # print_report(report2)\n",
    "\n",
    "def print_report(report: Dict[str, Any]):\n",
    "    \"\"\"Helper function to neatly print the agent's report.\"\"\"\n",
    "    print(\"\\nâœ… FINAL AGENT REPORT:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"An error occurred: {report['error']}\")\n",
    "        print(f\"Raw Output: {report.get('raw_output')}\")\n",
    "    else:\n",
    "        print(f\"ðŸ† Overall Quality Score: {report.get('overall_score', 'N/A')} / 10\")\n",
    "        \n",
    "        # Check for contextual errors\n",
    "        contextual_errors = report.get('contextual_errors', [])\n",
    "        if contextual_errors:\n",
    "            print(\"\\nðŸš¨ CONTEXTUAL ERRORS DETECTED:\")\n",
    "            for error in contextual_errors:\n",
    "                print(f\"   âŒ {error}\")\n",
    "        \n",
    "        print(\"\\n--- Category Breakdown ---\")\n",
    "        category_scores = report.get('category_scores', {})\n",
    "        score_explanations = report.get('score_explanations', {})\n",
    "        \n",
    "        for category, score in category_scores.items():\n",
    "            category_name = category.replace('_', ' ').title()\n",
    "            explanation = score_explanations.get(category, \"No explanation provided.\")\n",
    "            print(f\"   - {category_name}: {score}/10\")\n",
    "            print(f\"     â””â”€ {explanation}\")\n",
    "        \n",
    "        print(\"\\n--- Summary & Suggestions ---\")\n",
    "        print(report.get('summary', 'No summary provided.'))\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Run the main async function\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cb7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: This is a \\\"test\\\" with unwanted \\n characters!\n",
      "Cleaned: This is a test with unwanted characters!\n",
      "ðŸš€ Initializing Paragraph Quality Agent...\n",
      "\n",
      "ðŸ“ Original Paragraph:\n",
      "'This is a \"sample paragraph\" with \\n unwanted characters and \\t formatting issues. \n",
      "    It contains some https://example.com/long-url-here and other artifacts like [brackets] and {braces}.\n",
      "    The text also has    excessive   spacing and multiple....dots!!!'\n",
      "Length: 257 characters\n",
      "\n",
      "âœ¨ Cleaned Paragraph:\n",
      "'This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!'\n",
      "Length: 194 characters\n",
      "Removed: 63 characters\n",
      "\n",
      "ðŸ” Running full quality analysis...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CleanText` with `This is a \"sample paragraph\" with \n",
      " unwanted characters and \t formatting issues. \n",
      "    It contains some https://example.com/long-url-here and other artifacts like [brackets] and {braces}.\n",
      "    The text also has    excessive   spacing and multiple....dots!!!`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"cleaned_text\": \"This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!\", \"original_length\": 255, \"cleaned_length\": 194, \"characters_removed\": 61}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `GrammarAndSpellingCheck` with `This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!`\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check grammar...\n",
      "\u001b[33;1m\u001b[1;3m{\n",
      "    \"errors\": [\n",
      "        \"Unwanted characters and formatting issues mentioned but not specified\",\n",
      "        \"Vague phrasing 'some and other artifacts'\",\n",
      "        \"Excessive spacing indicated but not shown in the text\",\n",
      "        \"Ellipsis used incorrectly; should be three dots, not multiple\"\n",
      "    ],\n",
      "    \"score\": 6,\n",
      "    \"score_explanation\": \"The text contains several vague phrases and issues with punctuation, particularly with the ellipsis. While the overall message is clear, the lack of specificity and clarity in describing the issues detracts from the quality.\"\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ReadabilityCheck` with `This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m{\"flesch_reading_ease_score\": 45.32678160919542, \"level\": \"Difficult\", \"readability_score\": 6, \"score_explanation\": \"Readability score: 6/10. Flesch score of 45.3 indicates difficult reading level.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ProfessionalismCheck` with `This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3m{\"issues\": [], \"score\": 10, \"score_explanation\": \"Professionalism score: 10/10. 0 professional issues detected.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `LengthAndStructureCheck` with `This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"word_count\": 29, \"sentences\": 4, \"paragraphs\": 1, \"issues\": [], \"score\": 10, \"score_explanation\": \"Structure score: 10/10. Based on 29 words, 4 sentences, 1 paragraphs.\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `RedundancyCheck` with `This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{\"redundancy_issues\": [], \"score\": 10, \"score_explanation\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': 'https://example.com/long-url-here'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'title': 'What does this structure of the URL mean? http://www.example.com ...', 'url': 'https://wordpress.stackexchange.com/questions/226685/what-does-this-structure-of-the-url-mean-http-www-example-com-i-0', 'content': \"\\\\ Chat\\n\\\\ Contact\\n\\\\ Feedback\\n##### Company\\n\\\\ Stack Overflow\\n\\\\ Teams\\n\\\\ Advertising\\n\\\\ Talent\\n\\\\ About\\n\\\\ Press\\n\\\\ Legal\\n\\\\ Privacy Policy\\n\\\\ Terms of Service\\n\\\\ Your Privacy Choices\\n\\\\ Cookie Policy\\n##### Stack Exchange Network\\n\\\\ Technology\\n\\\\ Culture & recreation\\n\\\\ Life & arts\\n\\\\ Science\\n\\\\ Professional\\n\\\\ Business\\n\\\\ API\\n\\\\ Data\\n\\\\ Blog\\n\\\\ Facebook\\n\\\\ Twitter\\n\\\\ LinkedIn\\n\\\\ Instagram\\nSite design / logo Â© 2025 Stack Exchange Inc; user contributions licensed under CC BY-SA. rev 2025.8.27.33312 [...] It contains harassment, bigotry or abuse.\\nThis comment attacks a person or group. Learn more in our Code of Conduct.\\nIt's unfriendly or unkind.\\nThis comment is rude or condescending. Learn more in our Code of Conduct.\\nNot needed.\\nThis comment is not relevant to the post.\\nEnter at least 6 characters\\nSomething else.\\nA problem not listed above. Try to be as specific as possible.\\nEnter at least 6 characters\\nFlag comment Cancel\\nYou have 0 flags left today\\n##### WordPress Development\\n\\\\ Tour\\n\\\\ Help [...] Follow this question to receive notifications\\nedited May 16, 2016 at 17:16\\nImage 11: unor's user avatar\\nunor\\n153 8 8 bronze badges\\nasked May 15, 2016 at 14:05\\nImage 12: tal's user avatar\\ntaltal\\n41 1 1 silver badge 5 5 bronze badges\\n2\\n\\\\ Is this WordPress? â€“TheDeadMedic Commented May 15, 2016 at 14:23\\n\\\\ yes it's WordPress â€“tal Commented May 15, 2016 at 14:58\\nAdd a comment|\", 'score': 0.22805373}, {'title': \"URLs: It's complicated... - netmeister.org\", 'url': 'https://www.netmeister.org/blog/urls.html', 'content': 'go.example.com  redirect  to   wherever you want, say   ensure users have \"search example.com\" in   /etc/resolv.conf (or equivalent)   Now the only slightly confusing part here is that unless you run your own CA, you can\\'t get a certificate for \"go\", so the short links must be accessed using plain http. But either way, you see that the \"hostname\" component in a URL need not be fully qualified. Port The \"authority\" component may further contain a \"port\" subcomponent. I\\'m sure you\\'ve seen that in [...] is plenty of room for abuse here: imagine a URL like  which may trick a user into thinking that the site they\\'re connecting to is trustworthy. Phishers gonna phish.  Also note that the set of characters allowed in either the \"username\" or \"password\" filed here allows many characters that would not be allowed in a normal \"hostname\" component (although do see this post for what is and isn\\'t \"valid\" there). Per RFC3986:  ``` userinfo    = ( unreserved / pct-encoded / sub-delims / \":\" ) unreserved [...] also be the full URL itself, not just the \"pathname\" component. RFC7230 in fact mandates this when talking to a proxy:  ``` $ openssl s_client -connect www.netmeister.org:443 -quiet -crlf 2>/dev/null HEAD  HTTP/1.0  HTTP/1.1 200 OK Date: Mon, 21 Jun 2021 18:36:39 GMT Server: Apache/2.4.43 (Unix) OpenSSL/1.1.1k Last-Modified: Mon, 21 Jun 2021 18:24:38 GMT Content-Length: 29963 Content-Type: text/html; charset=utf-8  ```  And if you\\'re not talking to a proxy, you can just put any', 'score': 0.15407057}, {'title': 'Redirects and Google Search | Documentation', 'url': 'https://developers.google.com/search/docs/crawling-indexing/301-redirects', 'content': 'If server-side redirects aren\\'t possible to implement on your platform, `meta refresh` redirects may be a viable alternative. Google differentiates between two kinds of `meta refresh` redirects: [...] If you have access to your web server configuration files, you may be able to write the redirect rules yourself. Follow your web server\\'s guides:\\n\\n Apache: Consult the Apache `.htaccess` Tutorial, the Apache URL Rewriting Guide, and the Apache `mod_alias` documentation. For example, you can use `mod_alias` to set up the simplest form of redirects:\\n\\n  ```\\n  # Permanent redirect: Redirect permanent \"/old\" \" # Temporary redirect: Redirect temp \"/two-old\" \"\\n  ``` [...] This helps users find your new site and Google may understand this as a crypto redirect, (like the Loch Ness monster, its existence may be disputed; not all search engines may recognize this pseudo-redirect as an official redirect).\\n\\n## Alternate versions of a URL', 'score': 0.12458555}]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "    \"overall_score\": 7,\n",
      "    \"cleaned_text\": \"This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!\",\n",
      "    \"original_vs_cleaned\": {\n",
      "        \"original_length\": 255,\n",
      "        \"cleaned_length\": 194,\n",
      "        \"characters_removed\": 61\n",
      "    },\n",
      "    \"category_scores\": {\n",
      "        \"grammar_and_spelling\": 6,\n",
      "        \"readability\": 6,\n",
      "        \"professionalism_and_tone\": 10,\n",
      "        \"factual_accuracy\": 5,\n",
      "        \"redundancy\": 10,\n",
      "        \"content_structure\": 10\n",
      "    },\n",
      "    \"score_explanations\": {\n",
      "        \"grammar_and_spelling\": \"The text contains several vague phrases and issues with punctuation, particularly with the ellipsis. While the overall message is clear, the lack of specificity and clarity in describing the issues detracts from the quality.\",\n",
      "        \"readability\": \"Readability score: 6/10. Flesch score of 45.3 indicates difficult reading level.\",\n",
      "        \"professionalism_and_tone\": \"Professionalism score: 10/10. 0 professional issues detected.\",\n",
      "        \"factual_accuracy\": \"The URL provided is a placeholder and does not lead to a verifiable source, affecting the factual accuracy score.\",\n",
      "        \"redundancy\": \"Redundancy score: 10/10. Unique sentence ratio: 1.00.\",\n",
      "        \"content_structure\": \"Structure score: 10/10. Based on 29 words, 4 sentences, 1 paragraph.\"\n",
      "    },\n",
      "    \"issues_found\": [\n",
      "        \"Unwanted characters and formatting issues mentioned but not specified\",\n",
      "        \"Vague phrasing 'some and other artifacts'\",\n",
      "        \"Excessive spacing indicated but not shown in the text\",\n",
      "        \"Ellipsis used incorrectly; should be three dots, not multiple\",\n",
      "        \"URL is a placeholder and does not lead to a verifiable source\"\n",
      "    ],\n",
      "    \"summary\": \"The paragraph has a moderate overall quality score of 7. It is well-structured and professional, but it suffers from vague language and punctuation issues. To improve, clarify the descriptions of the unwanted characters and formatting issues, ensure proper use of ellipses, and replace the placeholder URL with a valid one.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š PARAGRAPH QUALITY ANALYSIS REPORT\n",
      "============================================================\n",
      "ðŸ† Overall Quality Score: 7/10\n",
      "\n",
      "ðŸ§¹ Text Cleaning Results:\n",
      "   Original length: 255 characters\n",
      "   Cleaned length: 194 characters\n",
      "   Characters removed: 61\n",
      "\n",
      "âœ¨ Cleaned Text:\n",
      "   'This is a sample paragraph with unwanted characters and formatting issues. It contains some and other artifacts like brackets and braces. The text also has excessive spacing and multiple...dots!'\n",
      "\n",
      "ðŸ“Š Category Scores:\n",
      "   Grammar And Spelling: 6/10\n",
      "   Readability: 6/10\n",
      "   Professionalism And Tone: 10/10\n",
      "   Factual Accuracy: 5/10\n",
      "   Redundancy: 10/10\n",
      "   Content Structure: 10/10\n",
      "\n",
      "ðŸ’¡ Summary:\n",
      "   The paragraph has a moderate overall quality score of 7. It is well-structured and professional, but it suffers from vague language and punctuation issues. To improve, clarify the descriptions of the unwanted characters and formatting issues, ensure proper use of ellipses, and replace the placeholder URL with a valid one.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TEXT CLEANING FUNCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def clean_paragraph_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans paragraph text by removing unwanted characters, escape sequences, and formatting issues.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove escape characters\n",
    "    text = text.replace('\\\\\"', '\"')\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "    text = text.replace('\\\\t', ' ')\n",
    "    text = text.replace('\\\\r', '')\n",
    "    text = text.replace('\\\\\\\\', '\\\\')\n",
    "    \n",
    "    # Remove JSON-like artifacts\n",
    "    text = re.sub(r'[{}[\\]\"]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://[^\\s]+', '', text)\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove excessive punctuation\n",
    "    text = re.sub(r'[.]{3,}', '...', text)\n",
    "    text = re.sub(r'[!]{2,}', '!', text)\n",
    "    text = re.sub(r'[?]{2,}', '?', text)\n",
    "    \n",
    "    # Remove special characters that don't belong in normal text\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:()\\-\\'\\\"]+', '', text)\n",
    "    \n",
    "    # Clean up line breaks and spacing\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "        score -= 3\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "        score -= 2\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"word_count\": word_count, \n",
    "        \"sentences\": len(sentences), \n",
    "        \"paragraphs\": len(paragraphs), \n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Structure score: {max(1, score)}/10. Based on {word_count} words, {len(sentences)} sentences, {len(paragraphs)} paragraphs.\"\n",
    "    })\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond with a JSON object with:\n",
    "    - \"errors\": [\"list of concise error descriptions\"]\n",
    "    - \"score\": integer from 1-10 (10 = perfect, deduct points for each error)\n",
    "    - \"score_explanation\": brief explanation of why this score was given\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_readability_with_textstat(text: str) -> str:\n",
    "    \"\"\"Uses the 'textstat' library to calculate objective readability scores.\"\"\"\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\", \"readability_score\": 1, \"score_explanation\": \"Cannot assess readability of empty text.\"})\n",
    "    \n",
    "    flesch_score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    readability_score = 10\n",
    "    \n",
    "    if flesch_score < 30: \n",
    "        level = \"Very Confusing (College Graduate)\"\n",
    "        readability_score = 3\n",
    "    elif flesch_score < 60: \n",
    "        level = \"Difficult\"\n",
    "        readability_score = 6\n",
    "    elif flesch_score < 80: \n",
    "        level = \"Fairly Easy\"\n",
    "        readability_score = 8\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"flesch_reading_ease_score\": flesch_score, \n",
    "        \"level\": level,\n",
    "        \"readability_score\": readability_score,\n",
    "        \"score_explanation\": f\"Readability score: {readability_score}/10. Flesch score of {flesch_score:.1f} indicates {level.lower()} reading level.\"\n",
    "    })\n",
    "\n",
    "def check_professionalism(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content like profanity, slang, or excessive formatting.\"\"\"\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "        score -= 5\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "        score -= 3\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "        score -= 2\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"issues\": issues,\n",
    "        \"score\": max(1, score),\n",
    "        \"score_explanation\": f\"Professionalism score: {max(1, score)}/10. {len(issues)} professional issues detected.\"\n",
    "    })\n",
    "\n",
    "def check_redundancy(text: str) -> str:\n",
    "    \"\"\"Analyzes the text for repetitive sentences and overused words.\"\"\"\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    issues = []\n",
    "    score = 10\n",
    "    \n",
    "    if len(sentences) > 2:\n",
    "        redundancy_ratio = len(set(sentences)) / len(sentences)\n",
    "        if redundancy_ratio < 0.5:\n",
    "            redundancy_percentage = 100 - redundancy_ratio*100\n",
    "            issues.append(f\"High sentence redundancy detected. {redundancy_percentage:.0f}% of sentences are repetitive.\")\n",
    "            score = max(1, int(redundancy_ratio * 10))\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"redundancy_issues\": issues,\n",
    "        \"score\": score,\n",
    "        \"score_explanation\": f\"Redundancy score: {score}/10. Unique sentence ratio: {(len(set(sentences)) / max(1, len(sentences))):.2f}\"\n",
    "    })\n",
    "\n",
    "def clean_text_tool(text: str) -> str:\n",
    "    \"\"\"Tool function to clean paragraph text.\"\"\"\n",
    "    cleaned = clean_paragraph_text(text)\n",
    "    return json.dumps({\n",
    "        \"cleaned_text\": cleaned,\n",
    "        \"original_length\": len(text),\n",
    "        \"cleaned_length\": len(cleaned),\n",
    "        \"characters_removed\": len(text) - len(cleaned)\n",
    "    })\n",
    "\n",
    "# ==============================================================================\n",
    "#  SIMPLIFIED AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ParagraphQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "            Tool(name=\"CleanText\", func=clean_text_tool, description=\"Use to clean and remove unwanted characters from text.\"),\n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism, description=\"Use to check a piece of text for unprofessional language.\"),\n",
    "            Tool(name=\"LengthAndStructureCheck\", func=check_length_and_structure, description=\"Use to get word count and structure of a piece of text.\"),\n",
    "            Tool(name=\"RedundancyCheck\", func=check_redundancy, description=\"Use to check a piece of text for repetitive sentences.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Use to verify factual claims in a piece of text.\")\n",
    "        ]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Text Quality Analyst. Your goal is to clean and analyze paragraph text.\n",
    "\n",
    "            **Your Process:**\n",
    "            1. First, use the CleanText tool to remove unwanted characters and clean the input text\n",
    "            2. Then run quality analysis on the cleaned text using all available tools:\n",
    "               - Grammar and Spelling Check\n",
    "               - Readability Check  \n",
    "               - Professionalism Check\n",
    "               - Length and Structure Check\n",
    "               - Redundancy Check\n",
    "               - Fact Check (if needed for factual claims)\n",
    "\n",
    "            **FINAL ANSWER FORMATTING:**\n",
    "            Your final answer MUST be a single JSON object:\n",
    "            {{\n",
    "                \"overall_score\": <integer 1-10>,\n",
    "                \"cleaned_text\": \"<the cleaned version of the input text>\",\n",
    "                \"original_vs_cleaned\": {{\n",
    "                    \"original_length\": <number>,\n",
    "                    \"cleaned_length\": <number>,\n",
    "                    \"characters_removed\": <number>\n",
    "                }},\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <1-10>,\n",
    "                    \"readability\": <1-10>,\n",
    "                    \"professionalism_and_tone\": <1-10>,\n",
    "                    \"factual_accuracy\": <1-10>,\n",
    "                    \"redundancy\": <1-10>,\n",
    "                    \"content_structure\": <1-10>\n",
    "                }},\n",
    "                \"score_explanations\": {{\n",
    "                    \"grammar_and_spelling\": \"<explanation>\",\n",
    "                    \"readability\": \"<explanation>\",\n",
    "                    \"professionalism_and_tone\": \"<explanation>\",\n",
    "                    \"factual_accuracy\": \"<explanation>\",\n",
    "                    \"redundancy\": \"<explanation>\",\n",
    "                    \"content_structure\": \"<explanation>\"\n",
    "                }},\n",
    "                \"issues_found\": [\"<list of issues>\"],\n",
    "                \"summary\": \"<overall quality summary and improvement suggestions>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def analyze_paragraph_async(self, paragraph: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyzes a paragraph after cleaning it.\"\"\"\n",
    "        \n",
    "        prompt = f\"Please clean and analyze the following paragraph:\\n---\\n{paragraph}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            # Extract JSON from response\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during analysis: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output generated.')}\n",
    "\n",
    "    def analyze_paragraph_sync(self, paragraph: str) -> Dict[str, Any]:\n",
    "        \"\"\"Synchronous version of paragraph analysis.\"\"\"\n",
    "        \n",
    "        # Clean the text first\n",
    "        cleaned_text = clean_paragraph_text(paragraph)\n",
    "        \n",
    "        # Simple quality analysis without agent (for quick results)\n",
    "        return {\n",
    "            \"overall_score\": 8,  # This would be calculated based on individual scores\n",
    "            \"cleaned_text\": cleaned_text,\n",
    "            \"original_vs_cleaned\": {\n",
    "                \"original_length\": len(paragraph),\n",
    "                \"cleaned_length\": len(cleaned_text),\n",
    "                \"characters_removed\": len(paragraph) - len(cleaned_text)\n",
    "            },\n",
    "            \"summary\": f\"Text cleaned successfully. Removed {len(paragraph) - len(cleaned_text)} unwanted characters.\"\n",
    "        }\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: API keys must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Paragraph Quality Agent...\")\n",
    "    analyzer = ParagraphQualityAgent()\n",
    "    \n",
    "    # Example paragraph with unwanted characters\n",
    "    test_paragraph = \"\"\"This is a \\\"sample paragraph\\\" with \\\\n unwanted characters and \\\\t formatting issues. \n",
    "    It contains some https://example.com/long-url-here and other artifacts like [brackets] and {braces}.\n",
    "    The text also has    excessive   spacing and multiple....dots!!!\"\"\"\n",
    "    \n",
    "    print(f\"\\nðŸ“ Original Paragraph:\")\n",
    "    print(f\"'{test_paragraph}'\")\n",
    "    print(f\"Length: {len(test_paragraph)} characters\")\n",
    "    \n",
    "    # Clean the text first (quick version)\n",
    "    cleaned = clean_paragraph_text(test_paragraph)\n",
    "    print(f\"\\nâœ¨ Cleaned Paragraph:\")\n",
    "    print(f\"'{cleaned}'\")\n",
    "    print(f\"Length: {len(cleaned)} characters\")\n",
    "    print(f\"Removed: {len(test_paragraph) - len(cleaned)} characters\")\n",
    "    \n",
    "    # Full analysis with agent\n",
    "    print(f\"\\nðŸ” Running full quality analysis...\")\n",
    "    report = await analyzer.analyze_paragraph_async(test_paragraph)\n",
    "    print_report(report)\n",
    "\n",
    "def print_report(report: Dict[str, Any]):\n",
    "    \"\"\"Print the analysis report.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š PARAGRAPH QUALITY ANALYSIS REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"âŒ Error: {report['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ðŸ† Overall Quality Score: {report.get('overall_score', 'N/A')}/10\")\n",
    "    \n",
    "    # Show cleaning results\n",
    "    cleaning_info = report.get('original_vs_cleaned', {})\n",
    "    if cleaning_info:\n",
    "        print(f\"\\nðŸ§¹ Text Cleaning Results:\")\n",
    "        print(f\"   Original length: {cleaning_info.get('original_length', 0)} characters\")\n",
    "        print(f\"   Cleaned length: {cleaning_info.get('cleaned_length', 0)} characters\")\n",
    "        print(f\"   Characters removed: {cleaning_info.get('characters_removed', 0)}\")\n",
    "    \n",
    "    # Show cleaned text\n",
    "    cleaned_text = report.get('cleaned_text', '')\n",
    "    if cleaned_text:\n",
    "        print(f\"\\nâœ¨ Cleaned Text:\")\n",
    "        print(f\"   '{cleaned_text[:200]}{'...' if len(cleaned_text) > 200 else ''}'\")\n",
    "    \n",
    "    # Show category scores\n",
    "    category_scores = report.get('category_scores', {})\n",
    "    if category_scores:\n",
    "        print(f\"\\nðŸ“Š Category Scores:\")\n",
    "        for category, score in category_scores.items():\n",
    "            print(f\"   {category.replace('_', ' ').title()}: {score}/10\")\n",
    "    \n",
    "    # Show summary\n",
    "    summary = report.get('summary', '')\n",
    "    if summary:\n",
    "        print(f\"\\nðŸ’¡ Summary:\")\n",
    "        print(f\"   {summary}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "# For standalone text cleaning function\n",
    "def clean_text_simple(text: str) -> str:\n",
    "    \"\"\"Simple function to clean text and return result.\"\"\"\n",
    "    return clean_paragraph_text(text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can also use it simply like this:\n",
    "    sample_text = \"This is a \\\\\\\"test\\\\\\\" with unwanted \\\\n characters!\"\n",
    "    cleaned = clean_text_simple(sample_text)\n",
    "    print(f\"Original: {sample_text}\")\n",
    "    print(f\"Cleaned: {cleaned}\")\n",
    "    \n",
    "    # Or run the full analysis\n",
    "    await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
