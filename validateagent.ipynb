{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68330e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "# --- New Imports for Modern Agent and Tools ---\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat # Library for readability scores\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS (Separated for clarity)\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes content length and structure (word count, paragraphs).\n",
    "    This is fast and rule-based, perfect for a custom tool.\n",
    "    Returns a JSON string with the analysis.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "\n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "\n",
    "    return json.dumps({\"word_count\": word_count, \"sentences\": len(sentences), \"paragraphs\": len(paragraphs), \"issues\": issues})\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses a powerful LLM to check for grammar and spelling errors.\n",
    "    This is more accurate than a fixed list of regex patterns.\n",
    "    Returns a JSON string listing the errors found.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond with a JSON object containing one key, \"errors\", which is a list of strings.\n",
    "    Each string should describe a specific error you found. If no errors, return an empty list.\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_readability_with_textstat(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the 'textstat' library to calculate objective readability scores.\n",
    "    This is a custom tool enhanced with a specialized library.\n",
    "    Returns a JSON string with the Flesch Reading Ease score and interpretation.\n",
    "    \"\"\"\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\"})\n",
    "    \n",
    "    score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    if score < 30:\n",
    "        level = \"Very Confusing (College Graduate)\"\n",
    "    elif score < 60:\n",
    "        level = \"Difficult\"\n",
    "    elif score < 80:\n",
    "        level = \"Fairly Easy\"\n",
    "    return json.dumps({\"flesch_reading_ease_score\": score, \"level\": level})\n",
    "\n",
    "def check_professionalism(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Checks for unprofessional content like profanity, slang, or excessive formatting.\n",
    "    This is fast and rule-based, perfect for a custom tool.\n",
    "    Returns a JSON string with a list of professionalism issues.\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    # Check for profanity\n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "    # Check for \"shouting\" (excessive capitalization)\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "    # Check for excessive punctuation\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "    return json.dumps({\"issues\": issues})\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  THE REFACTORED AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        \"\"\"Setup an agent with a mix of built-in and custom tools.\"\"\"\n",
    "        \n",
    "        # 1. Define the tools list\n",
    "        tools = [\n",
    "            # --- BUILT-IN TOOL ---\n",
    "            TavilySearchResults(\n",
    "                name=\"FactCheckSearch\",\n",
    "                max_results=3,\n",
    "                description=\"Use this tool to search the web to verify factual claims, check for misinformation, or find context on a topic.\"\n",
    "            ),\n",
    "            # --- UPGRADED & CUSTOM TOOLS ---\n",
    "            Tool(\n",
    "                name=\"GrammarAndSpellingCheck\",\n",
    "                func=check_grammar_with_llm,\n",
    "                description=\"Use this to check a piece of text for spelling and grammatical errors.\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"ReadabilityCheck\",\n",
    "                func=check_readability_with_textstat,\n",
    "                description=\"Use this to get the readability score and complexity level of a text.\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"ProfessionalismCheck\",\n",
    "                func=check_professionalism,\n",
    "                description=\"Use this to check for unprofessional language, like profanity, excessive capitalization, or slang.\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"LengthAndStructureCheck\",\n",
    "                func=check_length_and_structure,\n",
    "                description=\"Use this to get basic statistics like word count and paragraph structure.\"\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        # 2. Create the agent's prompt template\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are an expert Quality Assurance assistant. Your goal is to provide a complete and accurate quality report on the user's text. Use your tools to check all aspects of the content. First, form a plan, then execute your plan by calling the necessary tools. Finally, compile all the results into a comprehensive final answer summarizing your findings.\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        # 3. Create the agent\n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        \n",
    "        # 4. Create the Agent Executor to run the agent\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    def validate(self, text_to_validate: str) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent to perform a full quality analysis.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Please provide a comprehensive quality analysis of the following text.\n",
    "        Your final answer should be a summary of all findings.\n",
    "\n",
    "        Text to Analyze:\n",
    "        ---\n",
    "        {text_to_validate}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        return self.agent_executor.invoke({\"input\": prompt})\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: OPENAI_API_KEY and TAVILY_API_KEY must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "\n",
    "    sample_text = \"\"\"\n",
    "    BREAKING NEWS!!! The goverment has SECRETLEY been using 5G towers to controll our minds and make us buy more STUFF we dont need!!! This is CIENTIFICALY proven by my frend who works at Area 51 and he told me that aliens are actualy running Facebook and Google to steal our THOUGHTS!!! Mark Zuckerberg is definatley an alien REPTILIAN who eats babys for breakfast FACT!!! Wake up SHEEPLE the truth is RIGHT THERE!!!! #conspiracy #truth #wakeup !@#$%^&*()\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ” Running Full Analysis...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    result = validator.validate(sample_text)\n",
    "    \n",
    "    print(\"\\nâœ… FINAL AGENT REPORT:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(result['output'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    # This function is now focused on a single piece of text\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "    return json.dumps({\"word_count\": word_count, \"sentences\": len(sentences), \"paragraphs\": len(paragraphs), \"issues\": issues})\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond with a JSON object: {{\"errors\": [\"list of concise error descriptions\"]}}. If no errors, return an empty list.\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_readability_with_textstat(text: str) -> str:\n",
    "    \"\"\"Uses the 'textstat' library to calculate objective readability scores.\"\"\"\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\"})\n",
    "    score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    if score < 30: level = \"Very Confusing (College Graduate)\"\n",
    "    elif score < 60: level = \"Difficult\"\n",
    "    elif score < 80: level = \"Fairly Easy\"\n",
    "    return json.dumps({\"flesch_reading_ease_score\": score, \"level\": level})\n",
    "\n",
    "def check_professionalism(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content like profanity, slang, or excessive formatting.\"\"\"\n",
    "    issues = []\n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "    return json.dumps({\"issues\": issues})\n",
    "\n",
    "def check_redundancy(text: str) -> str:\n",
    "    \"\"\"Analyzes the text for repetitive sentences and overused words.\"\"\"\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    issues = []\n",
    "    if len(sentences) > 2:\n",
    "        redundancy_ratio = len(set(sentences)) / len(sentences)\n",
    "        if redundancy_ratio < 0.5:\n",
    "            issues.append(f\"High sentence redundancy detected. {100 - redundancy_ratio*100:.0f}% of sentences are repetitive.\")\n",
    "    return json.dumps({\"redundancy_issues\": issues})\n",
    "\n",
    "def check_itext_payload_faithfulness(payload_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes an iText JSON payload. It checks for consistency between the message and data,\n",
    "    and evaluates the faithfulness and relevance between the 'content', 'simplified', and 'elaborated' versions.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Using LLM to analyze iText payload...\")\n",
    "    try:\n",
    "        payload = json.loads(payload_str)\n",
    "        message = payload.get(\"message\", \"\")\n",
    "        content_data = payload.get(\"data\", [{}])[0].get(\"data\", {})\n",
    "        original = content_data.get(\"content\", \"\")\n",
    "        simplified = content_data.get(\"simplified\", \"\")\n",
    "        elaborated = content_data.get(\"elaborated\", \"\")\n",
    "    except (json.JSONDecodeError, IndexError, KeyError) as e:\n",
    "        return json.dumps({\"error\": f\"Invalid iText payload structure: {e}\"})\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert iText payload evaluator. Analyze the following payload:\n",
    "    Message: \"{message}\"\n",
    "    Original Content: \"{original}\"\n",
    "    Simplified Content: \"{simplified}\"\n",
    "    Elaborated Content: \"{elaborated}\"\n",
    "\n",
    "    Evaluate two things:\n",
    "    1.  **Consistency**: Does the content seem to match the message (e.g., a \"success\" message with valid content)?\n",
    "    2.  **Faithfulness & Relevance**: Compare the three text versions. Do the simplified/elaborated versions maintain the original meaning without adding incorrect info?\n",
    "\n",
    "    Return ONLY a JSON object with your findings, like this:\n",
    "    {{\n",
    "        \"consistency_check\": \"<Brief summary of consistency>\",\n",
    "        \"faithfulness_score\": <int 1-10>,\n",
    "        \"relevance_score\": <int 1-10>,\n",
    "        \"comparison_summary\": \"<Brief summary of how the versions differ>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# ==============================================================================\n",
    "#  AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o-mini\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "            Tool(name=\"iTextPayloadFaithfulnessCheck\", func=check_itext_payload_faithfulness, description=\"Use this ONLY for a JSON input representing an iText payload. It checks faithfulness between content versions.\"),\n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism, description=\"Use to check a piece of text for unprofessional language.\"),\n",
    "            Tool(name=\"LengthAndStructureCheck\", func=check_length_and_structure, description=\"Use to get word count and structure of a piece of text.\"),\n",
    "            Tool(name=\"RedundancyCheck\", func=check_redundancy, description=\"Use to check a piece of text for repetitive sentences.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=3, description=\"Use to verify factual claims in a piece of text.\")\n",
    "        ]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Quality Assurance assistant. Your goal is to provide a complete quality report.\n",
    "\n",
    "            You will receive one of two types of input:\n",
    "            1.  A plain text paragraph.\n",
    "            2.  A JSON string representing an \"iText payload\".\n",
    "\n",
    "            **Your Plan:**\n",
    "            - If the input is an iText payload (JSON), you MUST use the `iTextPayloadFaithfulnessCheck` tool on the entire JSON. You should ALSO run standard checks (grammar, professionalism, etc.) on the 'content' field within the payload.\n",
    "            - If the input is plain text, just run the standard checks on it.\n",
    "            \n",
    "            After executing your plan, compile all results into the final JSON report.\n",
    "\n",
    "            **FINAL ANSWER FORMATTING INSTRUCTIONS:**\n",
    "            Your final answer MUST be a single JSON object with the specified structure.\n",
    "            {{\n",
    "                \"overall_score\": <An integer score from 1-10>,\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <Score 1-10>,\n",
    "                    \"readability\": <Score 1-10>,\n",
    "                    \"professionalism_and_tone\": <Score 1-10>,\n",
    "                    \"factual_accuracy\": <Score 1-10. Default to 10 if no claims to check.>,\n",
    "                    \"redundancy\": <Score 1-10>,\n",
    "                    \"faithfulness\": <Score 1-10. Only applies to iText. Default to 10 for plain text.>\n",
    "                }},\n",
    "                \"summary\": \"<A natural language summary of key issues and suggestions for improvement.>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def validate_async(self, input_data: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent asynchronously on either a string or a dictionary.\"\"\"\n",
    "        \n",
    "        if isinstance(input_data, dict):\n",
    "            # It's an iText payload, serialize it to a string for the agent\n",
    "            input_str = json.dumps(input_data, indent=2)\n",
    "            analysis_subject = \"the following iText payload\"\n",
    "        else:\n",
    "            # It's a plain paragraph\n",
    "            input_str = input_data\n",
    "            analysis_subject = \"the following text\"\n",
    "            \n",
    "        prompt = f\"Please provide a comprehensive quality analysis of {analysis_subject}:\\n---\\n{input_str}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            # Use regex to find the JSON object in case the LLM adds extra text\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: API keys must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "    \n",
    "    # # --- CASE 1: Plain Paragraph ---\n",
    "    # paragraph_to_analyze = \"\"\"\n",
    "    # Machine learning is the most revolutionary technology ever created and will solve all human problems. However, machine learning is completely useless and will never work properly. AI systems are incredibly intelligent. AI is actually very stupid. Neural networks are perfect. Neural networks are terrible.\n",
    "    # \"\"\"\n",
    "    # print(\"\\n\\nðŸ” Running analysis on Plain Paragraph...\")\n",
    "    # print(\"=\" * 60)\n",
    "    # report1 = await validator.validate_async(paragraph_to_analyze)\n",
    "    # print_report(report1)\n",
    "\n",
    "    # --- CASE 2: iText Payload ---\n",
    "    itext_payload = {\n",
    "        \"message\": \"Successfully generated iText block data.\",\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"type\": \"iText\",\n",
    "                \"data\": {\n",
    "                    \"content\": \"The sun is a star at the center of the Solar System. It is a nearly perfect ball of hot plasma. The Sun's diameter is about 109 times that of Earth.\",\n",
    "                    \"simplified\": \"The sun is a big star in the middle of our solar system.\",\n",
    "                    \"elaborated\": \"The Sun, a G-type main-sequence star (G2V), is the focal point of our Solar System. Comprising over 99.8% of the system's mass, it is an immense sphere of incandescent plasma, with a diameter of approximately 1.39 million kilometers, roughly 109 times that of our planet, which is a big lie.\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    print(\"\\n\\nðŸ” Running analysis on iText Payload...\")\n",
    "    print(\"=\" * 60)\n",
    "    report2 = await validator.validate_async(itext_payload)\n",
    "    print_report(report2)\n",
    "\n",
    "\n",
    "def print_report(report: Dict[str, Any]):\n",
    "    \"\"\"Helper function to neatly print the agent's report.\"\"\"\n",
    "    print(\"\\nâœ… FINAL AGENT REPORT:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"An error occurred: {report['error']}\")\n",
    "        print(f\"Raw Output: {report.get('raw_output')}\")\n",
    "    else:\n",
    "        print(f\"ðŸ† Overall Quality Score: {report.get('overall_score', 'N/A')} / 10\")\n",
    "        print(\"\\n--- Category Breakdown ---\")\n",
    "        for category, score in report.get('category_scores', {}).items():\n",
    "            category_name = category.replace('_', ' ').title()\n",
    "            print(f\"   - {category_name}: {score}/10\")\n",
    "        \n",
    "        print(\"\\n--- Summary & Suggestions ---\")\n",
    "        print(report.get('summary', 'No summary provided.'))\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Run the main async function\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, List, Union\n",
    "import asyncio\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "# TOOL LOGIC FUNCTIONS (Made async for concurrent execution)\n",
    "# ==============================================================================\n",
    "\n",
    "async def check_length_and_structure(text: str) -> str:\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "    return json.dumps({\"word_count\": word_count, \"sentences\": len(sentences), \"paragraphs\": len(paragraphs), \"issues\": issues})\n",
    "\n",
    "\n",
    "async def check_grammar_with_llm(text: str) -> str:\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    # Use a cheaper/faster model for simple tasks\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond ONLY with JSON: {{\"errors\": [\"list of concise error descriptions\"]}}. If no errors, return an empty list.\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = await checker_llm.ainvoke(prompt)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"errors\": [f\"LLM call failed: {e}\"]})\n",
    "\n",
    "\n",
    "async def check_readability_with_textstat(text: str) -> str:\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\"})\n",
    "    score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    if score < 30: level = \"Very Confusing (College Graduate)\"\n",
    "    elif score < 60: level = \"Difficult\"\n",
    "    elif score < 80: level = \"Fairly Easy\"\n",
    "    return json.dumps({\"flesch_reading_ease_score\": score, \"level\": level})\n",
    "\n",
    "\n",
    "async def check_professionalism(text: str) -> str:\n",
    "    issues = []\n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "    # Adjusted regex to be more accurate for excessive caps\n",
    "    if sum(1 for c in text if c.isupper()) / len(text.replace(\" \", \"\")) > 0.4 and len(text) > 20:\n",
    "         issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "    if re.search(r'[!?@#$%^&*()_+=]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "    return json.dumps({\"issues\": issues})\n",
    "\n",
    "\n",
    "async def check_redundancy(text: str) -> str:\n",
    "    sentences = [s.lower().strip() for s in re.split(r'[.!?]+', text) if len(s.strip().split()) > 3]\n",
    "    issues = []\n",
    "    if len(sentences) > 2:\n",
    "        # Using a more robust check for redundancy\n",
    "        unique_sentences = set(sentences)\n",
    "        redundancy_ratio = len(unique_sentences) / len(sentences)\n",
    "        if redundancy_ratio < 0.6:\n",
    "            issues.append(f\"High sentence redundancy detected. {100 - redundancy_ratio*100:.0f}% of sentences seem repetitive.\")\n",
    "    return json.dumps({\"redundancy_issues\": issues})\n",
    "\n",
    "\n",
    "async def check_faithfulness_and_relevance(payload: Dict[str, Any]) -> str:\n",
    "    \"\"\"Compare original vs simplified and elaborated text.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check faithfulness and relevance...\")\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    content = payload.get(\"content\", \"\")\n",
    "    simplified = payload.get(\"simplified\", \"\")\n",
    "    elaborated = payload.get(\"elaborated\", \"\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert text evaluator. Compare these three versions of content:\n",
    "    [Original] {content}\n",
    "    [Simplified] {simplified}\n",
    "    [Elaborated] {elaborated}\n",
    "\n",
    "    Evaluate on a scale of 1-10 (1=bad, 10=excellent) and provide a summary.\n",
    "    1. Faithfulness â€” Do simplified/elaborated keep the original meaning?\n",
    "    2. Relevance â€” Are they contextually correct and not adding wrong info?\n",
    "    3. Accuracy â€” Are there factual or conceptual mistakes?\n",
    "\n",
    "    Return ONLY JSON with this exact structure:\n",
    "    {{\n",
    "        \"faithfulness\": <int>,\n",
    "        \"relevance\": <int>,\n",
    "        \"accuracy\": <int>,\n",
    "        \"summary\": \"<short explanation of issues or differences>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = await llm.ainvoke(prompt)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"faithfulness\": 1, \"relevance\": 1, \"accuracy\": 1,\n",
    "            \"summary\": f\"LLM call failed: {e}\"\n",
    "        })\n",
    "\n",
    "# ==============================================================================\n",
    "# VALIDATOR CLASS (Replaces the Agent)\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityValidator:\n",
    "    def __init__(self, model=\"gpt-4o\", temperature=0.1):\n",
    "        # Use a powerful model for the final synthesis step\n",
    "        self.synthesis_llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "\n",
    "    async def validate_async(self, input_data: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Runs all checks concurrently and synthesizes a final report.\n",
    "        \"\"\"\n",
    "        tasks = []\n",
    "        is_itext = isinstance(input_data, dict) and \"content\" in input_data\n",
    "\n",
    "        # Use the 'content' field for standard checks if available, otherwise use the whole input\n",
    "        text_to_check = input_data.get(\"content\") if is_itext else input_data\n",
    "\n",
    "        # --- 1. GATHER DATA FROM ALL CHECKS ---\n",
    "        tasks.append(check_grammar_with_llm(text_to_check))\n",
    "        tasks.append(check_readability_with_textstat(text_to_check))\n",
    "        tasks.append(check_professionalism(text_to_check))\n",
    "        tasks.append(check_redundancy(text_to_check))\n",
    "        tasks.append(check_length_and_structure(text_to_check))\n",
    "        \n",
    "        if is_itext:\n",
    "            tasks.append(check_faithfulness_and_relevance(input_data))\n",
    "\n",
    "        # Run all tasks in parallel\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        # --- 2. PREPARE CONTEXT FOR SYNTHESIS ---\n",
    "        context = {\n",
    "            \"grammar_and_spelling_report\": json.loads(results[0]),\n",
    "            \"readability_report\": json.loads(results[1]),\n",
    "            \"professionalism_report\": json.loads(results[2]),\n",
    "            \"redundancy_report\": json.loads(results[3]),\n",
    "            \"length_and_structure_report\": json.loads(results[4]),\n",
    "        }\n",
    "        if is_itext:\n",
    "            context[\"faithfulness_and_relevance_report\"] = json.loads(results[5])\n",
    "        \n",
    "        # --- 3. SYNTHESIZE THE FINAL REPORT ---\n",
    "        print(\"ðŸ§  Synthesizing final report...\")\n",
    "        synthesis_prompt = f\"\"\"\n",
    "        You are an intelligent QA Analyst. Based on the following raw data from various quality checks,\n",
    "        generate a final JSON report.\n",
    "\n",
    "        Your task is to convert the raw data into category scores from 1-10 (1=very poor, 10=excellent)\n",
    "        and write a concise summary with actionable improvement suggestions.\n",
    "\n",
    "        Raw Data:\n",
    "        {json.dumps(context, indent=2)}\n",
    "\n",
    "        - For `grammar_and_spelling`, if there are errors, score is low. No errors = 10.\n",
    "        - For `readability`, a \"Very Easy\" or \"Fairly Easy\" level is high-scoring (8-10). \"Difficult\" is 4-6. \"Very Confusing\" is 1-3.\n",
    "        - For `professionalism_and_tone`, any issues found should result in a low score. No issues = 10.\n",
    "        - For `redundancy`, any issues found means a lower score. No issues = 10.\n",
    "        - `factual_accuracy` is 10 by default unless faithfulness/relevance checks find issues.\n",
    "        - `faithfulness` and `relevance` scores should be taken directly from the report if present, otherwise set them to 10.\n",
    "\n",
    "        FINAL ANSWER must be ONLY the JSON object with the following structure:\n",
    "        {{\n",
    "            \"overall_score\": <int 1-10>,\n",
    "            \"category_scores\": {{\n",
    "                \"grammar_and_spelling\": <int 1-10>,\n",
    "                \"readability\": <int 1-10>,\n",
    "                \"professionalism_and_tone\": <int 1-10>,\n",
    "                \"factual_accuracy\": <int 1-10>,\n",
    "                \"redundancy\": <int 1-10>,\n",
    "                \"faithfulness\": <int 1-10>,\n",
    "                \"relevance\": <int 1-10>\n",
    "            }},\n",
    "            \"summary\": \"<summary of findings and concrete improvement suggestions>\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            final_response = await self.synthesis_llm.ainvoke(synthesis_prompt)\n",
    "            # Find the JSON object in the response, in case the LLM adds extra text\n",
    "            json_match = re.search(r'\\{.*\\}', final_response.content, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in the final response.\", final_response.content, 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error parsing final JSON response: {e}\")\n",
    "            return {\"error\": \"Invalid or failed final JSON synthesis\", \"raw_output\": final_response.content}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN\n",
    "# ==============================================================================\n",
    "async def main():\n",
    "    validator = ContentQualityValidator()\n",
    "\n",
    "    # # --- CASE 1: iText JSON payload ---\n",
    "    # itext_payload = {\n",
    "    #     \"message\": \"Successfully generated iText block data.\",\n",
    "    #     \"data\": [\n",
    "    #         {\n",
    "    #             \"type\": \"iText\",\n",
    "    #             \"data\": {\n",
    "    #                 \"content\": \"Foundations of Deep Learning serve as the bedrock for modern AI, encompassing neural networks, backpropagation, and activation functions. These principles enable machines to learn from vast datasets.\",\n",
    "    #                 \"simplified\": \"Deep learning is a type of machine learning that uses artificial neural networks to learn from data. It's the foundation of today's AI.\",\n",
    "    #                 \"elaborated\": \"The foundations of deep learning encompass a range of critical concepts, starting with the artificial neuron, the basic computational unit. These are organized into layers to form deep neural networks. The learning process is facilitated by an algorithm called backpropagation, which adjusts the network's parameters to minimize error, and non-linear activation functions like ReLU, which allow the network to model complex patterns. This is all a lie and the sky is green.\"\n",
    "    #             }\n",
    "    #         }\n",
    "    #     ]\n",
    "    # }\n",
    "\n",
    "    # print(\"\\nðŸš€ Evaluating iText payload...\")\n",
    "    # itext_data = itext_payload[\"data\"][0][\"data\"]\n",
    "    # report = await validator.validate_async(itext_data)\n",
    "    # print(json.dumps(report, indent=2))\n",
    "\n",
    "\n",
    "    # # --- CASE 2: plain paragraph \n",
    "# Run main\n",
    "if __name__ == \"__main__\":\n",
    "    await (main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8329151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running analysis on iText Payload...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ComprehensiveITextChecker` with `{\"message\": \"Generate the successful content regarding typescript.\", \"data\": [{\"type\": \"iText\", \"data\": {\"content\": \"Foundations of Deep Learning serve as the bedrock for understanding neural networks...\", \"simplified\": \"Deep learning is a type of machine learning that uses networks of nodes...\", \"elaborated\": \"The foundations of deep learning encompass a range of principles and practices...\"}}]}`\n",
      "\n",
      "\n",
      "\u001b[0mðŸ”¬ Performing comprehensive iText analysis...\n",
      "ðŸ§  Using LLM to check grammar...\n",
      "ðŸ§  Using LLM to check grammar...\n",
      "ðŸ§  Using LLM to check grammar...\n",
      "\u001b[36;1m\u001b[1;3m{\n",
      "  \"faithfulness_analysis\": {\n",
      "    \"faithfulness_score\": 7,\n",
      "    \"relevance_score\": 8,\n",
      "    \"comparison_summary\": \"The Original text provides a foundational perspective on deep learning, while the Simplified version distills the concept into basic terms, making it accessible but less detailed. The Elaborated version expands on the Original by discussing a broader range of principles and practices, thus offering more depth. Overall, the Simplified version sacrifices some detail for clarity, while the Elaborated version enhances the Original's content.\"\n",
      "  },\n",
      "  \"detailed_text_analysis\": {\n",
      "    \"original\": {\n",
      "      \"grammar_report\": {\n",
      "        \"errors\": []\n",
      "      },\n",
      "      \"readability_report\": {\n",
      "        \"flesch_reading_ease_score\": 46.60500000000002,\n",
      "        \"level\": \"Difficult\"\n",
      "      },\n",
      "      \"professionalism_report\": {\n",
      "        \"issues\": []\n",
      "      }\n",
      "    },\n",
      "    \"simplified\": {\n",
      "      \"grammar_report\": {\n",
      "        \"errors\": []\n",
      "      },\n",
      "      \"readability_report\": {\n",
      "        \"flesch_reading_ease_score\": 76.50153846153849,\n",
      "        \"level\": \"Fairly Easy\"\n",
      "      },\n",
      "      \"professionalism_report\": {\n",
      "        \"issues\": []\n",
      "      }\n",
      "    },\n",
      "    \"elaborated\": {\n",
      "      \"grammar_report\": {\n",
      "        \"errors\": []\n",
      "      },\n",
      "      \"readability_report\": {\n",
      "        \"flesch_reading_ease_score\": 46.60500000000002,\n",
      "        \"level\": \"Difficult\"\n",
      "      },\n",
      "      \"professionalism_report\": {\n",
      "        \"issues\": []\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"overall_score\": 8,\n",
      "    \"category_scores\": {\n",
      "        \"grammar_and_spelling\": 10,\n",
      "        \"readability\": 7,\n",
      "        \"professionalism_and_tone\": 10,\n",
      "        \"faithfulness\": 7\n",
      "    },\n",
      "    \"summary\": \"The iText content is grammatically sound and maintains a professional tone across all versions. The Original and Elaborated texts are difficult to read, with a Flesch Reading Ease score indicating a challenging level, while the Simplified version is more accessible with a 'Fairly Easy' score. The faithfulness analysis shows that the Simplified version effectively distills the core concepts but loses some detail, whereas the Elaborated version provides a more comprehensive view, enhancing the Original content. To improve, consider balancing detail and readability in the Original and Elaborated texts to make them more accessible without sacrificing depth.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "âœ… FINAL AGENT REPORT: iText Payload Analysis\n",
      "------------------------------------------------------------\n",
      "ðŸ† Overall Quality Score: 8 / 10\n",
      "\n",
      "--- Category Breakdown ---\n",
      "   - Grammar And Spelling: 10/10\n",
      "   - Readability: 7/10\n",
      "   - Professionalism And Tone: 10/10\n",
      "   - Faithfulness: 7/10\n",
      "\n",
      "--- Summary & Suggestions ---\n",
      "The iText content is grammatically sound and maintains a professional tone across all versions. The Original and Elaborated texts are difficult to read, with a Flesch Reading Ease score indicating a challenging level, while the Simplified version is more accessible with a 'Fairly Easy' score. The faithfulness analysis shows that the Simplified version effectively distills the core concepts but loses some detail, whereas the Elaborated version provides a more comprehensive view, enhancing the Original content. To improve, consider balancing detail and readability in the Original and Elaborated texts to make them more accessible without sacrificing depth.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    # ... (rest of the function is unchanged)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "    return json.dumps({\"word_count\": word_count, \"sentences\": len(sentences), \"paragraphs\": len(paragraphs), \"issues\": issues})\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond with a JSON object: {{\"errors\": [\"list of concise error descriptions\"]}}. If no errors, return an empty list.\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_readability_with_textstat(text: str) -> str:\n",
    "    \"\"\"Uses the 'textstat' library to calculate objective readability scores.\"\"\"\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\"})\n",
    "    score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    if score < 30: level = \"Very Confusing (College Graduate)\"\n",
    "    elif score < 60: level = \"Difficult\"\n",
    "    elif score < 80: level = \"Fairly Easy\"\n",
    "    return json.dumps({\"flesch_reading_ease_score\": score, \"level\": level})\n",
    "\n",
    "def check_professionalism(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content like profanity, slang, or excessive formatting.\"\"\"\n",
    "    issues = []\n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "    return json.dumps({\"issues\": issues})\n",
    "\n",
    "# This is now the \"super-tool\" for iText Payloads\n",
    "def comprehensive_itext_checker(payload_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a FULL analysis on an iText JSON payload. It checks faithfulness between versions\n",
    "    AND runs grammar, readability, and professionalism checks on the content, simplified, and elaborated texts.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”¬ Performing comprehensive iText analysis...\")\n",
    "    try:\n",
    "        payload = json.loads(payload_str)\n",
    "        content_data = payload.get(\"data\", [{}])[0].get(\"data\", {})\n",
    "        original = content_data.get(\"content\", \"\")\n",
    "        simplified = content_data.get(\"simplified\", \"\")\n",
    "        elaborated = content_data.get(\"elaborated\", \"\")\n",
    "    except (json.JSONDecodeError, IndexError, KeyError) as e:\n",
    "        return json.dumps({\"error\": f\"Invalid iText payload structure: {e}\"})\n",
    "\n",
    "    # --- 1. Perform Faithfulness Check with an LLM ---\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    faithfulness_prompt = f\"\"\"\n",
    "    You are an expert iText payload evaluator. Compare the following three text versions.\n",
    "    Evaluate their faithfulness and relevance on a scale of 1-10 and provide a summary.\n",
    "    [Original]: {original}\n",
    "    [Simplified]: {simplified}\n",
    "    [Elaborated]: {elaborated}\n",
    "    Return ONLY a JSON object with your findings.\n",
    "    {{\n",
    "        \"faithfulness_score\": <int 1-10>,\n",
    "        \"relevance_score\": <int 1-10>,\n",
    "        \"comparison_summary\": \"<Brief summary of how the versions differ>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    faithfulness_report = json.loads(llm.invoke(faithfulness_prompt).content)\n",
    "\n",
    "    # --- 2. Perform Standard Checks on Each Text Field ---\n",
    "    texts_to_check = {\n",
    "        \"original\": original,\n",
    "        \"simplified\": simplified,\n",
    "        \"elaborated\": elaborated\n",
    "    }\n",
    "    detailed_reports = {}\n",
    "    for key, text in texts_to_check.items():\n",
    "        if text: # Only run checks if the text exists\n",
    "            detailed_reports[key] = {\n",
    "                \"grammar_report\": json.loads(check_grammar_with_llm(text)),\n",
    "                \"readability_report\": json.loads(check_readability_with_textstat(text)),\n",
    "                \"professionalism_report\": json.loads(check_professionalism(text)),\n",
    "            }\n",
    "\n",
    "    # --- 3. Combine All Results ---\n",
    "    final_combined_report = {\n",
    "        \"faithfulness_analysis\": faithfulness_report,\n",
    "        \"detailed_text_analysis\": detailed_reports\n",
    "    }\n",
    "\n",
    "    return json.dumps(final_combined_report, indent=2)\n",
    "\n",
    "# ==============================================================================\n",
    "#  AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o\", temperature=0): # Use a powerful model for the final reasoning\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        # Note: We only provide the super-tool for iText now.\n",
    "        # The agent's job is simpler: pick the right tool for the job.\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"ComprehensiveITextChecker\",\n",
    "                func=comprehensive_itext_checker,\n",
    "                description=\"Use this ONLY for a JSON input representing an iText payload. This tool performs a complete analysis.\"\n",
    "            ),\n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of plain text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of plain text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism, description=\"Use to check a piece of plain text for unprofessional language.\"),\n",
    "        ]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Quality Assurance assistant. Your job is to create a final, summarized quality report in JSON format.\n",
    "\n",
    "            **Your Plan:**\n",
    "            - **If the input is an iText payload (JSON string):** Use the `ComprehensiveITextChecker` tool. This one tool will give you all the data you need.\n",
    "            - **If the input is plain text:** Use the standard tools like `GrammarAndSpellingCheck` and `ReadabilityCheck` to gather data.\n",
    "            \n",
    "            After getting the tool results, analyze them and create the final summary report as requested.\n",
    "\n",
    "            **FINAL ANSWER FORMATTING INSTRUCTIONS:**\n",
    "            Your final answer MUST be a single JSON object with the specified structure.\n",
    "            {{\n",
    "                \"overall_score\": <An integer score from 1-10>,\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <Score 1-10>,\n",
    "                    \"readability\": <Score 1-10>,\n",
    "                    \"professionalism_and_tone\": <Score 1-10>,\n",
    "                    \"faithfulness\": <Score 1-10. Default to 10 for plain text.>\n",
    "                }},\n",
    "                \"summary\": \"<A natural language summary of key issues and suggestions for improvement.>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def validate_async(self, input_data: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent asynchronously on either a string or a dictionary.\"\"\"\n",
    "        \n",
    "        if isinstance(input_data, dict):\n",
    "            input_str = json.dumps(input_data)\n",
    "            analysis_subject = \"the following iText payload\"\n",
    "        else:\n",
    "            input_str = input_data\n",
    "            analysis_subject = \"the following text\"\n",
    "            \n",
    "        prompt = f\"Please provide a comprehensive quality analysis of {analysis_subject}:\\n---\\n{input_str}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "def print_report(report: Dict[str, Any], title: str):\n",
    "    \"\"\"Helper function to neatly print the agent's report.\"\"\"\n",
    "    print(f\"\\nâœ… FINAL AGENT REPORT: {title}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"An error occurred: {report['error']}\")\n",
    "        print(f\"Raw Output: {report.get('raw_output')}\")\n",
    "    else:\n",
    "        print(f\"ðŸ† Overall Quality Score: {report.get('overall_score', 'N/A')} / 10\")\n",
    "        print(\"\\n--- Category Breakdown ---\")\n",
    "        for category, score in report.get('category_scores', {}).items():\n",
    "            category_name = category.replace('_', ' ').title()\n",
    "            print(f\"   - {category_name}: {score}/10\")\n",
    "        \n",
    "        print(\"\\n--- Summary & Suggestions ---\")\n",
    "        print(report.get('summary', 'No summary provided.'))\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"âŒ Error: OPENAI_API_KEY must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "    \n",
    "#     # --- CASE 1: Plain Paragraph ---\n",
    "#     paragraph_to_analyze = \"\"\"\n",
    "# Setting Up the Python Environment\n",
    "# Setting up the Python environment is the first step in embarking on your journey into Python programming. This process involves installing Python, configuring your system, and choosing the right tools for development. Python is a versatile language used in various fields, including web development, data analysis, artificial intelligence, and scientific computing. Therefore, having a well-configured environment is crucial for effective coding and project management.\n",
    "\n",
    "# Installing Python\n",
    "# The first step in setting up your Python environment is to install Python itself. Python can be downloaded from the official Python website at python.org. The installation process varies slightly depending on your operating system. For Windows, you can download the executable installer, run it, and ensure to check the box that says 'Add Python to PATH' during installation. For macOS, Python is often pre-installed, but you can install the latest version using Homebrew with the command brew install python. Linux users can install Python using their distribution's package manager, such as apt for Ubuntu or yum for Fedora.\n",
    "\n",
    "# Setting Up a Development Environment\n",
    "# After installing Python, the next step is to set up a development environment. This can be done using Integrated Development Environments (IDEs) or text editors. Popular IDEs for Python include PyCharm, Visual Studio Code, and Jupyter Notebook. Each of these tools offers unique features that enhance productivity. For instance, PyCharm provides advanced debugging tools, while Jupyter Notebook is excellent for data science projects due to its interactive nature. To install an IDE, simply download it from the official website and follow the installation instructions.\n",
    "\n",
    "# \"\"\"\n",
    "    \n",
    "\n",
    "#     print(\"=\" * 60)\n",
    "#     report1 = await validator.validate_async(paragraph_to_analyze)\n",
    "#     print_report(report1, \"Plain Paragraph Analysis\")\n",
    "\n",
    "    # --- CASE 2: iText Payload ---\n",
    "    itext_payload = {\n",
    "        \"message\": \"Generate the successful content regarding typescript.\",\n",
    "        \"data\": [{\"type\": \"iText\", \"data\": {\n",
    "            \"content\": \"Foundations of Deep Learning serve as the bedrock for understanding neural networks...\",\n",
    "            \"simplified\": \"Deep learning is a type of machine learning that uses networks of nodes...\",\n",
    "            \"elaborated\": \"The foundations of deep learning encompass a range of principles and practices...\"\n",
    "        }}]\n",
    "    }\n",
    "    print(\"\\n\\nðŸ” Running analysis on iText Payload...\")\n",
    "    print(\"=\" * 60)\n",
    "    report2 = await validator.validate_async(itext_payload)\n",
    "    print_report(report2, \"iText Payload Analysis\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    await(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35abfff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing Content Quality Agent...\n",
      "\n",
      "\n",
      "ðŸ” Running analysis on Plain Paragraph...\n",
      "============================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `GrammarAndSpellingCheck` with `Machine learning is the most revolutionary technology ever created and will solve all human problems. However, machine learning is completely useless and will never work properly. AI systems are incredibly intelligent and can outperform humans in every task. But AI is actually very stupid and makes constant mistakes. Deep learning models are 100% accurate all the time. Yet deep learning is fundamentally flawed and produces unreliable results. Neural networks are perfect. Neural networks are terrible.`\n",
      "\n",
      "\n",
      "\u001b[0mðŸ§  Using LLM to check grammar...\n",
      "\u001b[33;1m\u001b[1;3m{\"errors\": []}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ReadabilityCheck` with `Machine learning is the most revolutionary technology ever created and will solve all human problems. However, machine learning is completely useless and will never work properly. AI systems are incredibly intelligent and can outperform humans in every task. But AI is actually very stupid and makes constant mistakes. Deep learning models are 100% accurate all the time. Yet deep learning is fundamentally flawed and produces unreliable results. Neural networks are perfect. Neural networks are terrible.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m{\"flesch_reading_ease_score\": 37.14337500000002, \"level\": \"Difficult\"}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ProfessionalismCheck` with `Machine learning is the most revolutionary technology ever created and will solve all human problems. However, machine learning is completely useless and will never work properly. AI systems are incredibly intelligent and can outperform humans in every task. But AI is actually very stupid and makes constant mistakes. Deep learning models are 100% accurate all the time. Yet deep learning is fundamentally flawed and produces unreliable results. Neural networks are perfect. Neural networks are terrible.`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3m{\"issues\": []}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FactCheckSearch` with `{'query': 'Machine learning will solve all human problems'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Machine learning, explained', 'url': 'https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained', 'content': '*   [](https://www.facebook.com/dialog/share?app_id=197866067790470&display=popup&href=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&redirect_uri=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&quote=This%20pervasive%20and%20powerful%20form%20of%20artificial%20intelligence%20is%20changing%20every%20industry.%20Here%E2%80%99s%20what%20you%20need%20to%20know%20about%20the%20potential%20and%20limitations%20of%20machine%20learning%20and%20how%20it%E2%80%99s%20being%20used. *   [](https://twitter.com/intent/tweet?url=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&text=This%20pervasive%20and%20powerful%20form%20of%20artificial%20intelligence%20is%20changing%20every%20industry.%20Here%E2%80%99s%20what%20you%20need%20to%20know%20about%20the%20potential%20and%20limitations%20of%20machine%20learning%20and%20how%20it%E2%80%99s%20being%20%E2%80%A6&via=MITSloan \"Share on X\") *   [](https://www.linkedin.com/shareArticle?mini=true&url=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&title=Machine%20learning,%20explained%20&summary=This%20pervasive%20and%20powerful%20form%20of%20artificial%20intelligence%20is%20changing%20every%20industry.%20Here%E2%80%99s%20what%20you%20need%20to%20know%20about%20the%20potential%20and%20limitations%20of%20machine%20learning%20and%20how%20it%E2%80%99s%20being%20used.&source= \"Share on LinkedIn\") *   [print](https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained#) **Medical imaging and diagnostics.**Machine learning programs can be trained to [examine medical images or other information](https://www.pathai.com/) and look for certain markers of illness, like a tool that can [predict cancer risk](https://news.mit.edu/2021/robust-artificial-intelligence-tools-predict-future-cancer-0128) based on a mammogram. Ways to [fight against bias in machine learning](https://sloanreview.mit.edu/article/the-risk-of-machine-learning-bias-and-how-to-prevent-it/) including carefully vetting training data and putting [organizational support behind ethical artificial intelligence efforts,](https://sloanreview.mit.edu/article/putting-responsible-ai-into-practice/) like making sure your organization embraces [human-centered AI](https://mitsloan.mit.edu/ideas-made-to-matter/how-can-human-centered-ai-fight-bias-machines-and-people), the practice of seeking input from people of different backgrounds, experiences, and lifestyles when designing AI systems. *   [](https://www.facebook.com/dialog/share?app_id=197866067790470&display=popup&href=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&redirect_uri=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&quote=Machine%20learning%20is%20changing,%20or%20will%20change,%20every%20industry,%20and%20leaders%20need%20to%20understand%20the%20basic%20principles,%20the%20potential,%20and%20the%20limitations. *   [](https://twitter.com/intent/tweet?url=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&text=Machine%20learning%20is%20changing,%20or%20will%20change,%20every%20industry,%20and%20leaders%20need%20to%20understand%20the%20basic%20principles,%20the%20potential,%20and%20the%20limitations.&via=MITSloan \"Share on X\") *   [](https://www.linkedin.com/shareArticle?mini=true&url=https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained&title=Machine%20learning,%20explained%20&summary=Machine%20learning%20is%20changing,%20or%20will%20change,%20every%20industry,%20and%20leaders%20need%20to%20understand%20the%20basic%20principles,%20the%20potential,%20and%20the%20limitations.&source= \"Share on LinkedIn\")', 'score': 0.98514}, {'title': '30 Major Machine Learning Limitations, Challenges & Risks', 'url': 'https://onix-systems.com/blog/limitations-of-machine-learning-algorithms', 'content': 'Stakeholders must also understand that ML models use patterns learned from historical data and canâ€™t offer meaningful insights or predictions about things outside the scope of their training data or generalize to new situations or contexts. Leakages of machine-generated data, such as machine-translated texts and AI-generated images, into training datasets introduce new challenges to machine learning development. Although the most commonly discussed ML systems are trained on static datasets, active and online learning have models updated when new data becomes available. *â€œOnixâ€™s developers have consistently demonstrated expertise, innovation, and responsibility in tackling complexities and challenges in machine learning and data science for the benefit of our clients and advancement of AI technologies,â€* said Oleksii Sheremet, the Tech Lead at Onixâ€™s ML Department.', 'score': 0.97911}]\u001b[0m\u001b[32;1m\u001b[1;3mBased on the analysis of the provided text, here is the comprehensive quality report:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"overall_score\": 4,\n",
      "    \"category_scores\": {\n",
      "        \"grammar_and_spelling\": 10,\n",
      "        \"readability\": 4,\n",
      "        \"professionalism_and_tone\": 8,\n",
      "        \"factual_accuracy\": 2,\n",
      "        \"faithfulness\": 10\n",
      "    },\n",
      "    \"specific_mistakes\": [\n",
      "        \"Factual error: Machine learning is not capable of solving all human problems.\",\n",
      "        \"Factual error: Deep learning models are not 100% accurate all the time.\",\n",
      "        \"Factual error: AI systems do not outperform humans in every task.\"\n",
      "    ],\n",
      "    \"improvement_suggestions\": [\n",
      "        \"Provide balanced and substantiated claims about machine learning and AI.\",\n",
      "        \"Avoid contradictory statements to improve clarity and coherence.\",\n",
      "        \"Include evidence or references to support claims about AI capabilities.\"\n",
      "    ],\n",
      "    \"overall_summary\": \"The text contains several factual inaccuracies and contradictory statements about machine learning and AI. While the grammar and spelling are correct, the readability is low due to the complexity and contradictions in the content. The text lacks factual accuracy, as it makes exaggerated claims about AI capabilities without evidence. To improve, the text should provide balanced views and substantiated claims.\"\n",
      "}\n",
      "```\n",
      "\n",
      "This report highlights the need for factual accuracy and coherence in discussing complex topics like machine learning and AI.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "âœ… FINAL AGENT REPORT: Conspiracy Paragraph Analysis\n",
      "------------------------------------------------------------\n",
      "ðŸ† Overall Quality Score: 4 / 10\n",
      "\n",
      "--- Category Breakdown ---\n",
      "   - Grammar And Spelling: 10/10\n",
      "   - Readability: 4/10\n",
      "   - Professionalism And Tone: 8/10\n",
      "   - Factual Accuracy: 2/10\n",
      "   - Faithfulness: 10/10\n",
      "\n",
      "--- Specific Mistakes Found ---\n",
      "   - Factual error: Machine learning is not capable of solving all human problems.\n",
      "   - Factual error: Deep learning models are not 100% accurate all the time.\n",
      "   - Factual error: AI systems do not outperform humans in every task.\n",
      "\n",
      "--- Improvement Suggestions ---\n",
      "   - Provide balanced and substantiated claims about machine learning and AI.\n",
      "   - Avoid contradictory statements to improve clarity and coherence.\n",
      "   - Include evidence or references to support claims about AI capabilities.\n",
      "\n",
      "--- Overall Summary ---\n",
      "The text contains several factual inaccuracies and contradictory statements about machine learning and AI. While the grammar and spelling are correct, the readability is low due to the complexity and contradictions in the content. The text lacks factual accuracy, as it makes exaggerated claims about AI capabilities without evidence. To improve, the text should provide balanced views and substantiated claims.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import textstat\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ==============================================================================\n",
    "#  TOOL LOGIC FUNCTIONS (Unchanged)\n",
    "# ==============================================================================\n",
    "\n",
    "def check_length_and_structure(text: str) -> str:\n",
    "    \"\"\"Analyzes content length and structure (word count, paragraphs).\"\"\"\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    issues = []\n",
    "    if word_count < 15:\n",
    "        issues.append(f\"Content is very short with only {word_count} words.\")\n",
    "    if word_count > 150 and len(paragraphs) == 1:\n",
    "        issues.append(\"Long content is not broken into paragraphs, making it hard to read.\")\n",
    "    if len(sentences) < 2 and word_count > 20:\n",
    "        issues.append(\"Content consists of a single long sentence; consider breaking it up.\")\n",
    "    return json.dumps({\"word_count\": word_count, \"sentences\": len(sentences), \"paragraphs\": len(paragraphs), \"issues\": issues})\n",
    "\n",
    "def check_grammar_with_llm(text: str) -> str:\n",
    "    \"\"\"Uses a powerful LLM to check for grammar and spelling errors.\"\"\"\n",
    "    print(\"ðŸ§  Using LLM to check grammar...\")\n",
    "    checker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert proofreader. Analyze the following text for grammar and spelling mistakes.\n",
    "    Respond with a JSON object: {{\"errors\": [\"list of concise error descriptions\"]}}. If no errors, return an empty list.\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    response = checker_llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def check_readability_with_textstat(text: str) -> str:\n",
    "    \"\"\"Uses the 'textstat' library to calculate objective readability scores.\"\"\"\n",
    "    if not text.strip():\n",
    "        return json.dumps({\"score\": 0, \"level\": \"unassessable\"})\n",
    "    score = textstat.flesch_reading_ease(text)\n",
    "    level = \"Very Easy\"\n",
    "    if score < 30: level = \"Very Confusing (College Graduate)\"\n",
    "    elif score < 60: level = \"Difficult\"\n",
    "    elif score < 80: level = \"Fairly Easy\"\n",
    "    return json.dumps({\"flesch_reading_ease_score\": score, \"level\": level})\n",
    "\n",
    "def check_professionalism(text: str) -> str:\n",
    "    \"\"\"Checks for unprofessional content like profanity, slang, or excessive formatting.\"\"\"\n",
    "    issues = []\n",
    "    if re.search(r'\\b(fuck|shit|damn|bitch|asshole)\\b', text, re.IGNORECASE):\n",
    "        issues.append(\"Inappropriate or profane language was found.\")\n",
    "    if re.search(r'\\b[A-Z]{4,}\\b', text) and sum(1 for c in text if c.isupper()) / len(text) > 0.3:\n",
    "        issues.append(\"Excessive capitalization is used, which appears unprofessional.\")\n",
    "    if re.search(r'[!?@#$%^&*()]{4,}', text):\n",
    "        issues.append(\"Excessive punctuation or symbols are used.\")\n",
    "    return json.dumps({\"issues\": issues})\n",
    "\n",
    "def comprehensive_itext_checker(payload_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a FULL analysis on an iText JSON payload, including all sub-checks.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”¬ Performing comprehensive iText analysis...\")\n",
    "    # This function's logic remains the same as before.\n",
    "    try:\n",
    "        payload = json.loads(payload_str)\n",
    "        content_data = payload.get(\"data\", [{}])[0].get(\"data\", {})\n",
    "        original = content_data.get(\"content\", \"\")\n",
    "        simplified = content_data.get(\"simplified\", \"\")\n",
    "        elaborated = content_data.get(\"elaborated\", \"\")\n",
    "    except (json.JSONDecodeError, IndexError, KeyError) as e:\n",
    "        return json.dumps({\"error\": f\"Invalid iText payload structure: {e}\"})\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    faithfulness_prompt = f\"\"\"\n",
    "    You are an expert iText payload evaluator. Compare the following three text versions.\n",
    "    Evaluate their faithfulness and relevance on a scale of 1-10 and provide a summary.\n",
    "    [Original]: {original}\n",
    "    [Simplified]: {simplified}\n",
    "    [Elaborated]: {elaborated}\n",
    "    Return ONLY a JSON object with your findings.\n",
    "    {{\n",
    "        \"faithfulness_score\": <int 1-10>,\n",
    "        \"relevance_score\": <int 1-10>,\n",
    "        \"comparison_summary\": \"<Brief summary of how the versions differ>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    faithfulness_report = json.loads(llm.invoke(faithfulness_prompt).content)\n",
    "    texts_to_check = {\"original\": original, \"simplified\": simplified, \"elaborated\": elaborated}\n",
    "    detailed_reports = {}\n",
    "    for key, text in texts_to_check.items():\n",
    "        if text:\n",
    "            detailed_reports[key] = {\n",
    "                \"grammar_report\": json.loads(check_grammar_with_llm(text)),\n",
    "                \"readability_report\": json.loads(check_readability_with_textstat(text)),\n",
    "                \"professionalism_report\": json.loads(check_professionalism(text)),\n",
    "            }\n",
    "    final_combined_report = {\n",
    "        \"faithfulness_analysis\": faithfulness_report,\n",
    "        \"detailed_text_analysis\": detailed_reports\n",
    "    }\n",
    "    return json.dumps(final_combined_report, indent=2)\n",
    "\n",
    "# ==============================================================================\n",
    "#  AGENT CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ContentQualityAgent:\n",
    "    def __init__(self, model=\"gpt-4o\", temperature=0):\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.setup_agent()\n",
    "\n",
    "    def setup_agent(self):\n",
    "        tools = [\n",
    "            Tool(name=\"ComprehensiveITextChecker\", func=comprehensive_itext_checker, description=\"Use this ONLY for a JSON input representing an iText payload. This tool performs a complete analysis.\"),\n",
    "            Tool(name=\"GrammarAndSpellingCheck\", func=check_grammar_with_llm, description=\"Use to check a piece of plain text for spelling and grammatical errors.\"),\n",
    "            Tool(name=\"ReadabilityCheck\", func=check_readability_with_textstat, description=\"Use to get the readability score of a piece of plain text.\"),\n",
    "            Tool(name=\"ProfessionalismCheck\", func=check_professionalism, description=\"Use to check a piece of plain text for unprofessional language.\"),\n",
    "            TavilySearchResults(name=\"FactCheckSearch\", max_results=2, description=\"Use to verify factual claims, check for misinformation, or find context for a piece of plain text.\")\n",
    "        ]\n",
    "        \n",
    "        # --- MODIFIED PROMPT ---\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert Quality Assurance assistant. Your job is to create a final, summarized quality report in JSON format.\n",
    "\n",
    "            **Your Plan:**\n",
    "            - **If the input is an iText payload (JSON string):** Use the `ComprehensiveITextChecker` tool.\n",
    "            - **If the input is plain text:** Use tools like `GrammarAndSpellingCheck`, `ProfessionalismCheck`, and `FactCheckSearch` to gather data.\n",
    "            \n",
    "            After getting the tool results, analyze them and create the final summary report.\n",
    "\n",
    "            **FINAL ANSWER FORMATTING INSTRUCTIONS:**\n",
    "            Your final answer MUST be a single JSON object with the following structure.\n",
    "            {{\n",
    "                \"overall_score\": <An integer score from 1-10 based on all factors>,\n",
    "                \"category_scores\": {{\n",
    "                    \"grammar_and_spelling\": <Score 1-10. 10 is perfect.>,\n",
    "                    \"readability\": <Score 1-10. Higher Flesch score = higher rating.>,\n",
    "                    \"professionalism_and_tone\": <Score 1-10. Unprofessional content gets a very low score.>,\n",
    "                    \"factual_accuracy\": <Score 1-10. Misinformation must get a score of 1. If no claims to check, score 10.>,\n",
    "                    \"faithfulness\": <Score 1-10. Default to 10 for plain text.>\n",
    "                }},\n",
    "                \"specific_mistakes\": [\n",
    "                    \"<A list of specific errors found, e.g., 'Spelling error: `goverment` should be `government`'>\",\n",
    "                    \"<e.g., 'Factual error: The claim about 5G is unsubstantiated.'>\"\n",
    "                ],\n",
    "                \"improvement_suggestions\": [\n",
    "                    \"<A list of actionable suggestions, e.g., 'Proofread the text to correct all spelling mistakes.'>\",\n",
    "                    \"<e.g., 'Remove excessive capitalization and punctuation to appear more professional.'>\"\n",
    "                ],\n",
    "                \"overall_summary\": \"<A concise, natural language summary of the findings.>\"\n",
    "            }}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_openai_functions_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    async def validate_async(self, input_data: Union[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Runs the agent asynchronously on either a string or a dictionary.\"\"\"\n",
    "        if isinstance(input_data, dict):\n",
    "            input_str = json.dumps(input_data)\n",
    "            analysis_subject = \"the following iText payload\"\n",
    "        else:\n",
    "            input_str = input_data\n",
    "            analysis_subject = \"the following text\"\n",
    "            \n",
    "        prompt = f\"Please provide a comprehensive quality analysis of {analysis_subject}:\\n---\\n{input_str}\\n---\"\n",
    "        \n",
    "        result = {} \n",
    "        try:\n",
    "            result = await self.agent_executor.ainvoke({\"input\": prompt})\n",
    "            json_match = re.search(r'\\{.*\\}', result['output'], re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON object found in agent output.\", result['output'], 0)\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"âŒ Error during agent execution or parsing: {e}\")\n",
    "            return {\"error\": \"Failed to generate a valid report.\", \"raw_output\": result.get('output', 'No output was generated.')}\n",
    "\n",
    "# ==============================================================================\n",
    "#  MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "def print_report(report: Dict[str, Any], title: str):\n",
    "    \"\"\"Helper function to neatly print the agent's report.\"\"\"\n",
    "    print(f\"\\nâœ… FINAL AGENT REPORT: {title}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"An error occurred: {report['error']}\")\n",
    "        print(f\"Raw Output: {report.get('raw_output')}\")\n",
    "    else:\n",
    "        print(f\"ðŸ† Overall Quality Score: {report.get('overall_score', 'N/A')} / 10\")\n",
    "        print(\"\\n--- Category Breakdown ---\")\n",
    "        for category, score in report.get('category_scores', {}).items():\n",
    "            category_name = category.replace('_', ' ').title()\n",
    "            print(f\"   - {category_name}: {score}/10\")\n",
    "        \n",
    "        print(\"\\n--- Specific Mistakes Found ---\")\n",
    "        for mistake in report.get('specific_mistakes', ['None']):\n",
    "            print(f\"   - {mistake}\")\n",
    "            \n",
    "        print(\"\\n--- Improvement Suggestions ---\")\n",
    "        for suggestion in report.get('improvement_suggestions', ['None']):\n",
    "            print(f\"   - {suggestion}\")\n",
    "\n",
    "        print(\"\\n--- Overall Summary ---\")\n",
    "        print(report.get('overall_summary', 'No summary provided.'))\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "async def main():\n",
    "    if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"âŒ Error: API keys must be set in your .env file.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸš€ Initializing Content Quality Agent...\")\n",
    "    validator = ContentQualityAgent()\n",
    "    \n",
    "    # --- Using your new paragraph as the input ---\n",
    "    paragraph_to_analyze = \"\"\"\n",
    "Machine learning is the most revolutionary technology ever created and will solve all human problems. However, machine learning is completely useless and will never work properly. AI systems are incredibly intelligent and can outperform humans in every task. But AI is actually very stupid and makes constant mistakes. Deep learning models are 100% accurate all the time. Yet deep learning is fundamentally flawed and produces unreliable results. Neural networks are perfect. Neural networks are terrible.\"\"\"\n",
    "    print(\"\\n\\nðŸ” Running analysis on Plain Paragraph...\")\n",
    "    print(\"=\" * 60)\n",
    "    report1 = await validator.validate_async(paragraph_to_analyze)\n",
    "    print_report(report1, \"Conspiracy Paragraph Analysis\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await (main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
